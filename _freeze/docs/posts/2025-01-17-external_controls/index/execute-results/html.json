{
  "hash": "fd47903bc37c89ce5cfc6dc8460c5fdf",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"External Controls in Oncology Clinical Trials\"\nsubtitle: \"Are these things legitimate?\"\nauthor: \"Mark Zobeck\"\ndate: 2025-01-17\nimage: external_control.png\ncategories: [\"Causation & Clinical Trials\"]\nbibliography: references.bib \neditor: \n  markdown: \n    wrap: 72\n---\n\n\n![](external_control.png){.preview-image fig-align=\"center\" width=\"443\"}\n\n## Introduction\n\nExternal controls are, for better or worse, common in pediatric oncology\nclinical trials. I don’t love them. They are dangerous. However, there\nare arguments in their favor. In this post, I’ll briefly discuss what\nhistorical controls are, when their use might be justified, and why\nthey’re dangerous.\n\n## What are external controls?\n\nThe purpose of clinical trials is to evaluate the effect of a treatment\nin some population of patients. In a classic randomized clinical trial,\npatients who meet the study criteria are randomized to either receive\nthe standard of care for their disease or a new treatment. The outcome\nbetween the two groups is compared, and due to the miracle of\nrandomization, the treatment effect can be identified as the difference\nin the outcomes between the groups.\n\nExternal controls are a group of patients not enrolled in a clinical\ntrial but used as a comparison group for patients on a trial. The\ndifference between the outcomes for the controls and the treatment group\nis taken as the effect of treatment, much like the comparison with the\nstandard of care arm in a clinical trial. For valid comparisons, the\ncontrol group should look as similar as possible to those that could\nhave been enrolled in the trial. The group may be taken from a previous\nclinical trial, a patient registry, or other real-world data source. The\nkey limitation of this design is that external controls do not benefit\nfrom the wonders of randomization, which makes bias a much greater\ndanger when estimating the effect of treatment.\n\n## Why we might use external controls\n\nExternal controls are generally used when trialists cannot or should not\nenroll a comparison group for ethical reasons or because the disease is\nso rare. Below is a table briefly explaining three reasons that might\njustifying using external controls. I wouldn’t go so far as to call\nthese *good* reasons, but perhaps they are permissible\n[@marion_use_2023].\n\n### Permissible reasons\n\n|                                                                                                                                                                                                                                                                                                     |\n|------------------------------------------------------------------------|\n| **When Randomization to Placebo is Unethical**<br> In condition has with well-established, effective treatments, then randomizing patients to receive a placebo would be unethical. If investigators wish to measure the effect compared to no treatment then they may opt for an external control. |\n| **Rare Disease Research**<br>Rare diseases make it difficult to recruit sufficient numbers of participants to meet the power requirements for a trial. External controls may be used to reduce the size of the trial.                                                                               |\n| **Severe Outcomes or Vulnerable Populations**<br> Randomization may be viewed as unacceptable for diseases with particularly severe outcomes (e.g. terminal illness) or that affect vulnerable populations (e.g. children) even if there is no standard of care.                                    |\n\n: {.striped .hover}\n\n@collignon_implementing_2021 sums up the use cases for historical\n(external) controls in their conclusion:\n\n> The use of historical controls, therefore, is better suited for cases\n> of high unmet clinical need, where the disease course is well\n> characterized and the primary endpoint is objective.\n\n### Suspect reasons\n\nThere are also many suspicious reasons for using external control. One\nis that they reduce the time and costs associated with conducting a\ntrial. The problem with this reasoning is that the savings may be\nminimal. Enrolling 200 patients in a trial compared to 400 patients does\nnot reduce the budget by half, given the enormous fixed costs associated\nwith designing and opening trials. No matter how many patients are\nenrolled, the trial may have to be run for the same time when outcomes\nare measured over years, as with survival in oncology trials. While\nexternal controls might suggest savings, the benefits are not as\nadvertised.\n\nMore importantly, there is an enormous price to pay for the credibility\nof the trial’s results. Many sources of bias can confound the treatment\neffect and make clear conclusions impossible. A trial may go on for ten\nyears only to end in a collective, scientific shrug ¯\\\\\\_(ツ)\\_/¯.\n\n## Sources of bias from external controls\n\nExternal control’s fundamental problem is that they are not randomized,\nleaving many ways that they can introduce bias into the analysis.\nRandomization reveals a treatment effect by guaranteeing that only\nrandom chance determines which treatment patients receive. This ensures\nno residual confounding between treatment and the outcome of interest.\nIn the parlance of directed acyclic graphs (DAGs), randomization erases\nall back door paths between the treatment and the outcome. No such\nguarantees exist for external controls, and backdoor paths very likely\nexist between treatment and outcomes. I’ve drawn the DAG below to\nrepresent the essential structure of the problem. There are many other\nmore complex structures, but I find this to be a sufficient\nrepresentation of the basic concerns.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDiagrammeR::grViz(\"\n  digraph mrdag {\n    graph [rankdir=TB]\n\n    # Node definitions\n    node [shape=ellipse]\n    U [label='Patient Group']\n    X [label='Treatment']\n    Y [label='Outcome']\n    { rank = same; X Y }\n\n    # Edges\n    U -> X\n    U -> Y\n    X -> Y [minlen=3]\n  }\n\", height = 200)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"htmlwidget-439255d280303064f3ac\" style=\"width:100%;height:193px;\" class=\"grViz html-widget\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-439255d280303064f3ac\">{\"x\":{\"diagram\":\"\\n  digraph mrdag {\\n    graph [rankdir=TB]\\n\\n    # Node definitions\\n    node [shape=ellipse]\\n    U [label=\\\"Patient Group\\\"]\\n    X [label=\\\"Treatment\\\"]\\n    Y [label=\\\"Outcome\\\"]\\n    { rank = same; X Y }\\n\\n    # Edges\\n    U -> X\\n    U -> Y\\n    X -> Y [minlen=3]\\n  }\\n\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\nOne example of how patient groups could affect treatment and outcome is\nif the external control group is drawn from a registry of sicker and\nolder patients who tend to have worse outcomes than the group in the\ntrial that received the treatment. This situation could make the\ntreatment appear more effective than it truly is. There are many other\nsources of bias. The table below \\[adapted from [@burger_use_2021]\\],\nlists some of the main sources of bias and how to mitigate their effect.\n\n### Bias types\n\n| Type of Bias and Description                                                                                                           | Mitigation Strategy                                                                                                                                                                                                                                                                                                     |\n|---------------------------|---------------------------------------------|\n| **Selection Bias**<br>Clinical trial participants often have different characteristics compared to patients in routine care settings   | • Design trial eligibility criteria that can be clearly applied to real-world settings<br>• When selecting external controls, carefully match population characteristics<br>• Use statistical approaches like propensity scoring, inverse probability weighting, or g-computation to account for population differences |\n| **Calendar Time Bias**<br>Treatment outcomes can vary across different time periods due to evolution in medical practices              | • Select control patients from similar time periods as the trial<br>• Provide evidence that standard of care has remained stable<br>• If using historical controls, document stability of outcomes over relevant time periods                                                                                           |\n| **Regional Bias**<br>Patient outcomes may differ between geographical locations due to variations in healthcare delivery               | • Source control patients from comparable geographic regions<br>• Document that care standards are similar across regions<br>• If using different regions, demonstrate comparable outcome patterns                                                                                                                      |\n| **Assessment Bias**<br>Knowledge of treatment assignment can influence how outcomes are evaluated                                      | • Focus on objective endpoints where possible<br>• Consider independent outcome review processes<br>• Implement rigorous sensitivity analyses                                                                                                                                                                           |\n| **Different Endpoint Bias**<br>Clinical trial endpoints may be measured differently than in routine practice                           | • Ensure consistent endpoint definitions<br>• Obtain necessary documentation (e.g., imaging) to allow standardized assessments<br>• Account for differences in assessment frequency                                                                                                                                     |\n| **Immortal Time Bias**<br>Challenges in establishing comparable time zero points between trial and control patients                    | • Clearly define and align study entry time points<br>• Carefully evaluate potential biases in time-based analyses                                                                                                                                                                                                      |\n| **Retrospective Selection Bias**<br>Risk of selectively choosing external data or analysis approaches after seeing results             | • Pre-specify all selection criteria and analyses<br>• Document selection process transparently                                                                                                                                                                                                                         |\n| **Study Bias**<br>Trial participation itself can affect outcomes due to different care patterns                                        | • Consider selecting controls from similar clinical settings<br>• Document and account for differences in care delivery                                                                                                                                                                                                 |\n| **Between Study Variability**<br>High unexplained outcome variation across studies suggests presence of important uncontrolled factors | • Consider randomized design if high unexplained variability exists<br>• Carefully document and account for known sources of variation                                                                                                                                                                                  |\n| **Intercurrent Event Bias**<br>Events occurring after study entry can affect comparability                                             | • Apply consistent approaches to handling intercurrent events<br>• Consider multiple analytical approaches to test robustness                                                                                                                                                                                           |\n\n: {.striped .hover}\n\n## How to reduce bias when using external controls\n\nThe best way to reduce bias from external controls is an open area of\nresearch. This is a polite way of saying it’s complicated and a mess.\nIt’s complicated because these studies are not quite observational\nstudies, but they definitely aren’t randomized trials. Researchers have,\ntherefore, opted for a range of analytical techniques, including using\nthresholds, propensity scores, matching, and meta-analytic methods. A\nfull discussion of analytical options is outside the scope of this blog\npost, but see the references at the end for more. Regardless of the\nmethod used, the most important way to control bias is undoubtedly to\nselect an external control group that is a close comparison to the types\nof patients enrolled in the trial.\n\nAnalyzing data from these types of studies is also a mess because many\nuntoward motivations can sneak into the results. These studies can be\nused to justify regulatory approval for a drug or biomedical device.\nCompanies are motivated to represent their product in the best way\npossible because there is a pot of gold at the end of the quest for\nregulatory approval. Mixing a company’s profit margins with a high\ndimensional vector of bias sources and a flexible choice of analytical\ntechniques is a recipe for chaos.\n\n## Conclusion\n\nI think it’s possible to justify the use of external controls and glean\nuseful information from them in certain settings. Regulators have even\nbegun to admit them as evidence to justifty drug approval \\[see\n[@mishra-kalyani_external_2022] for examples\\]. But I also think it’s a\ngenerally rational policy to increase one’s skepticism about a study in\nproportion to the number of free researcher degrees of freedom with an\nadditional adjustment for the presence of motivated reasoning. Both are\npresent in abundance with external controls. So, it makes good sense to\nbring a strong scientific skepticism to these studies. In this blog,\nwe’ve outlined the many ways that bias influences their results. The\nburden of proof – a rightfully heavy one – should rest on the\ninvestigators to demonstrate their study design and analysis overcome\nthe many limitations of external controls.\n\n## References\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\n<script src=\"../../../site_libs/viz-1.8.2/viz.js\"></script>\n<link href=\"../../../site_libs/DiagrammeR-styles-0.2/styles.css\" rel=\"stylesheet\" />\n<script src=\"../../../site_libs/grViz-binding-1.0.11/grViz.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}