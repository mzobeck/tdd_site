---
title: "The Path to Useful and Trustworthy Clinical Prediction Models"
author: "Mark Zobeck"
date: 2025-01-21
#date-modified: "`r Sys.Date()`"
image: modeling.png
format: 
  html:
    self-contained: true 
    toc: true
    toc-location: right
    toc-depth: 3
mainfont: Palatino
echo: false
categories: ["Clinical Prediction Modeling"]
comments: 
  hypothesis: true
editor: 
  markdown: 
    wrap: 72
---

![](modeling.png){.preview-image fig-align="center" width="600"
height="392"}

# Introduction

Clinical prediction modeling, using data to predict patients' clinical
outcomes to improve medical decision-making, can be incredibly powerful
if done well. Modern medicine is awash in unused data. Information that
we can use to improve the lives of patients is everywhere if we just
knew how to distill it from the muck and mire of the everyday chaos of
clinical care. With it, we could:

-   More efficiently diagnose diseases without patients suffering
    through tortuous journeys in the medical system, bouncing from
    doctor to doctor with no answers.

-   More accurately predict the prognosis of diseases, providing
    information about what the future will hold.

-   Make optimal medical decisions, enabling patients and physicians to
    wrestle with the risks and benefits of different treatment options
    to make the best decisions.

-   Confirm what we know to clarify what we don't, accelerating progress
    in basic and translational science and identifying which clinical
    trials are actually worth doing.

All of these benefits are within our reach, if only we could harness the
ocean of data generated by the medical system every day to produce
trustworthy and reliable clinical prediction models.

# Unrealized potential

Classical methods of statistical prediction modeling for clinical
applications have existed for decades, such as multivariable linear
regression, logistic regression, ordinal regression, survival modeling,
etc. There is a vast literature covering all of the relevant statistical
and clinical aspects of developing such models, from sample size
calculations and model performance to decision theory and
implementation. The science of prediction modeling is very well
developed.

Yet, these methods have not realized their potential. They have been
used well for some applications and terribly for many others. Most
models are optimized for publication and not for clinical use. They are
developed to advance careers and not improve patient care. Even the good
ones are rarely implemented into clinical practice. Running code in
statistics software and writing a paper is vastly easier than changing
clinical care. Despite a well-developed science of prediction modeling,
the health system carries on largely ignorant of it.

# AI has made the situation worse

The rise of machine learning and AI has only worsened the situation. AI
has demonstrated blockbuster results in certain use cases, such as for
chatbots and applications in radiology and pathology. Yet, these do not
translate well to clinical prediction tasks. AI is ravenous for data
because it must train an incredible number of parameters. AI also craves
stability in the system it is learning to reproduce. If the behavior of
the system changes, the titanic algorithms struggles to adapt, like a
massive ship that turns in a slow, wide arc. Clinical medicine is the
opposite of this. Data are relatively sparse, and the underlying system
that generates it is built on quicksand. Structural change is the rule
rather than the exception. Moreover, the science of describing the
reliability and trustworthiness of AI models is not well developed. The
discipline is still grappling with key questions, such as causal
inference methods and how to represent uncertainty when data are
limited. AI methods that have produced headline success in some
applications do not translate to the complex, dynamic, and messy world
of clinical practice.

# Useful and trustworthy clinical prediction models

To realize clinical prediction modeling's potential, we need a method
for producing [useful]{.underline} predictions that patients and
providers can [trust]{.underline}.

**Useful predictions:**

-   *Answer a specific and valuable question.* Sometimes, prediction
    models produce answers to different questions than the user has in
    mind. Other times, models are developed that answer a question that
    is not valuable because the information makes no difference either
    in terms of actions that people might take or psychological benefit
    from the knowledge it gives.

-   *Support decisions*. People can use the predictions to decide what
    is the best next step. This process involves more than the
    predictions, such as utilities of outcomes and the context of
    actions. The output of the model should be readily usable by someone
    equipped with this information.

-   *Can be implemented by the health system.* If the model demands too
    many resources, for example requiring data, IT infrastructure, or
    specialized expert knowledge that is unavailable, then it cannot
    practically be implemented. Models must be designed with constraints
    in mind.

**Trustworthy predictions:**

-   *Provide the right kind of answers*. Predictions can be in the form
    of discrete categories or probabilities. The question it answers and
    the decisions it supports determine the best type of answer. The
    wrong type of answer can produce worse decisions.

-   *Are accurate.* They generally answer the modeling question
    correctly. This can be demonstrated by measures of overall model
    performance, discrimination (how well the model separates groups)
    and calibration (whether the value or probability of an outcome
    matches the observed values/probabilities).

-   *Have quantifiable uncertainty.* One can say that both the chance of
    getting heads on a coin toss and the chance of team winning a match
    for a sport you have never heard of and know nothing about is 50%,
    but you would be very certain about that statement for the coin and
    very uncertain for the sports team. That certainty matters as you
    make a decision, monitor results, and consider changing your mind
    about the right course of action. It also matters for whether or not
    the predictions can be improved my more work on the model.

-   *Are not overfit to the data.* Models can be too good at predicting
    the dataset that is used to train it. They will fall apart when
    making predictions with new data. Methods for internal validation
    during model development must be used to demonstrate that the
    performance remains acceptable when simulating its use on new
    datasets.

-   *Perform acceptably over time.* The dynamics of the health system
    that produce outcomes can change slowly or suddenly over time.
    Processes must be in place to monitor the model and respond when
    their performance degrades.

-   *Perform acceptably in new situations*. Model performance can vary
    tremendously when used in new situations, such as in different
    hospitals or different types of patients. The predictions must be
    shown to be trustworthy in new settings.

This is the path to developing valuable prediction modeling that help
patients. These are the minimal criteria. Yet classical models and ML/AI
can fail spectacularly at these points.

The path for ML/AI is more difficult than for the classical methods
because implementation in the health system, providing the right kinds
of answers, quantifying uncertainty, and not overfitting given the
amount of available data are all much greater challenges. Proponents of
AI/ML argue that their models are more accurate. Even granting this
point, which is debatable, the consequences of doing these things poorly
tend to negate any benefit from improved accuracy.

Achieving all of these properties is difficult regardless of the
approach. The time, effort, and money required to do this well generally
outweighs the benefit that an academic gains from publishing an analysis
and moving on to the next thing. The literature is filled with
descriptions of models that are accurate when predicting from the
training data but are otherwise useless and not worthy of anyone's
trust.

# To the future!

None of these are my original thoughts. There are many, meany people who
want to do this well and have rigorously worked through these ideas.
These points have been articulated and systematized for the wider
scientific community ([the TRIPOD+AI statement and its associated
references are a good starting
place](https://www.tripod-statement.org/)). This post is my process of
synthesizing these essential concepts for my own practice as both a
physician and data scientist.

These points should guide the integration of prediction models into
clinical practice, but they probably won't. Or at least they will only
partially. The publishing incentives to stop short of anything practical
are too great. Hype is much more effective at selling to healthcare
executives than a careful evaluation of how well a model performs. This
is boring nerd stuff.

Yet, useful and trustworthy modeling can win because reality is
unrelenting. Hype will come and go. Expensive AI products will be
purchased and found to be useless. Cycles of boom and bust will roll on.
Amidst the noise, the future will remain open. We won't stop craving
reliable predictions while we continuously proceed into the unknown.
Useful and trustworthy models will demonstrate their virtues as time
rolls on, and health systems will become better at recognizing their
value and more capable or supporting their implementation. The
opportunities are tremendous if only we can avoid the allure of short
term payoffs and do the hard work of demonstrating that a model truly
improves patient care.
