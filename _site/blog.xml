<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>The Doctor&#39;s Dialectic</title>
<link>https://www.thedoctorsdialectic.com/blog.html</link>
<atom:link href="https://www.thedoctorsdialectic.com/blog.xml" rel="self" type="application/rss+xml"/>
<description></description>
<image>
<url>https://www.thedoctorsdialectic.com/img/d_logo.jpg</url>
<title>The Doctor&#39;s Dialectic</title>
<link>https://www.thedoctorsdialectic.com/blog.html</link>
</image>
<generator>quarto-1.4.554</generator>
<lastBuildDate>Wed, 29 Jan 2025 06:00:00 GMT</lastBuildDate>
<item>
  <title>Gratitude reduces the complexity of modern life to make it more meaningful</title>
  <dc:creator>Mark Zobeck</dc:creator>
  <link>https://www.thedoctorsdialectic.com/docs/posts/2025-01-29-trial/</link>
  <description><![CDATA[ 




<p><img src="https://www.thedoctorsdialectic.com/docs/posts/2025-01-29-trial/modeling.png" class="preview-image img-fluid"></p>
<section id="the-contentification-of-life" class="level2">
<h2 class="anchored" data-anchor-id="the-contentification-of-life"><strong>The contentification of life</strong></h2>
<p>The world is increasingly filled with noise and nonsense, making it difficult to see what is valuable amid a torrent of trivialities. With the rise of social media, our attention has become an economic commodity. Four million new posts are made on Instagram every hour; 3.7 million new YouTube videos are uploaded every day. This is chump change compared to what’s coming. The rate of content production is going to increase exponentially as generative AI matures in consumer applications. And the contentification of the internet for the commodification of our attention has overflowed into the offline world. Everywhere we turn, we’re offered the chance to level up in our jobs, our relationships, our skills, or our goals (and on Facebook, for me, level up my hip mobility because I clicked on an ad about stretching once). There’s always more to see, more to learn, and more to do to maximize the moment and optimize our happiness. Almost all of this is a heap of rubbish. Yet there are always small, buried treasures that keep us coming back to rummage through the garbage.</p>
</section>
<section id="the-exponentiation-of-life" class="level2">
<h2 class="anchored" data-anchor-id="the-exponentiation-of-life"><strong>The exponentiation of life</strong></h2>
<p>Beyond the value of the content we produce, the speed of production also gives us heartburn. We humans, evolved in the cradle of the natural numbers, nourished as a species by the small positive integers that we found on our fingers and our toes, have difficulty handling the exponentiation of possible human experiences. There are so many things we could do. So many ways to spend our time. So many counterfactual worlds unfolding at ever increasing speeds ahead of us. Navigating life is increasingly complex, increasingly overwhelming. Our attention can’t handle it all.</p>
</section>
<section id="many-options-that-mostly-stink" class="level2">
<h2 class="anchored" data-anchor-id="many-options-that-mostly-stink"><strong>Many options that mostly stink</strong></h2>
<p>So, we have tons of ways we could spend our time, energy, and attention. Too many. Most of these options are garbage. But it’s hard to tell upfront what is worthless and what is valuable because attention is money, so everything is marketing. Everything has a new coat of paint and has been spritzed with perfume. What do we do when there are so many things we could do, but it’s hard to tell which are wastes of time? How do we reduce the dimensionality of our options with so much noisy data?</p>
</section>
<section id="gratitude-can-help" class="level2">
<h2 class="anchored" data-anchor-id="gratitude-can-help"><strong>Gratitude can help</strong></h2>
<p>Gratitude can help us focus on what is valuable. Being grateful for something implies a host of magnificent and healthy epistemic processes. For example, I’m grateful for my dog, Rosie. I’m particularly grateful that she’s acting less like a puppy and more like a productive member of my family’s household society. To tell you about my gratitude for my dog’s behavior, I had to first search through all sorts of things in my life I could tell you about. Rosie was easy to find in this search process. However the algorithm works, it was efficient and accurate - it didn’t take me long to come up with an example and I’m certain about my feeling here. To articulate my gratitude, I then had to particularize Rosie as an object of my attention. Rosie is not an abstract concept or just an idea. She became an object of my attention with properties and characteristics that I can describe. In other words, I focused on her to the exclusion of anything else. Once presented in my awareness, my relationship with her takes center stage. I’m grateful for her because of how we interact. Not just because of who she is or who I am but because of who we are together. We’re correlated statistically. What I think is associated with who she is. We’re coupled cybernetically. How she exists influences what I do. My gratitude is about our existence together - a dynamic, fluid, abstract-yet-influential relationship that helps to direct my experiences and actions over time.</p>
</section>
<section id="gratitude-as-a-signal-of-value" class="level2">
<h2 class="anchored" data-anchor-id="gratitude-as-a-signal-of-value"><strong>Gratitude as a signal of value</strong></h2>
<p>Rosie has helped me find what is valuable. My gratitude acted as both search and filter for finding something that has meaning to me. Easy, quick, accurate. It doesn’t matter how many more things I add to search through or how much more content humanity produces; it will still be easy to identify her - and a host of other good things in my life - as something I’m grateful for. This salience in my focus, this worthiness of attention that gratitude produces, is something I can only describe as meaningful. It fills that epistemic moment with a sense of value. Gratitude helps us find the signals of value in the noise of modern life.</p>
</section>
<section id="gratitude-as-dimensionality-reduction" class="level2">
<h2 class="anchored" data-anchor-id="gratitude-as-dimensionality-reduction"><strong>Gratitude as dimensionality reduction</strong></h2>
<p>To be grateful for Rosie, I also had to focus on her to the exclusion of anything else. There are many, perhaps uncountably infinite, things I could be grateful for. There are also many, perhaps uncountably infinite, ways that I could be grateful for Rosie. Relationships are dynamic. They change in quality over time. But from all of these possibilities, I could wrap my attention around a thing known as Rosie and describe her in a way that is comprehensible to you in just a few words. I could envelop the intricate complexities of our relationship, an immaterial thing, to communicate the positive experience I take from it. Considering how Rosie and I can move through life together, there are yet infinitely more ways that we could act and interact, and yet my gratitude at where we’ve been suggests possible futures that are valuable and that would make me grateful anew. In a sea of infinite options, gratitude has reduced the dimensions I must consider, helping me reflect on where I’ve been and chart a course for the future.</p>
</section>
<section id="gratitude-in-2024" class="level2">
<h2 class="anchored" data-anchor-id="gratitude-in-2024"><strong>Gratitude in 2024</strong></h2>
<p>This has been a meditation on part of life I find overwhelming. I want to do good stuff. I want to be good at the things I do. I want to have meaningful relationships. I want to live my life well. Many and more are the ways this could happen or could go wrong. There are so many dang options for how to spend my time. I’m extremely grateful for my dog, obviously, as well as my family, friends, job, and God. Gratitude helps me slow down, find those things that are meaningful, and savor the good dynamics of those relationships. It also helps me to think about how to nourish those good things so they bloom into something beautiful. Being grateful for what I’ve experienced in 2023 helps me plan what to do in 2024. I have goals, but gratitude suggests the purpose of planning isn’t to achieve goals but to help what is true, beautiful, and good in my life flourish.</p>


</section>

 ]]></description>
  <category>Musings &amp; Meditations</category>
  <guid>https://www.thedoctorsdialectic.com/docs/posts/2025-01-29-trial/</guid>
  <pubDate>Wed, 29 Jan 2025 06:00:00 GMT</pubDate>
  <media:content url="https://www.thedoctorsdialectic.com/docs/posts/2025-01-29-trial/modeling.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>The Path to Useful and Trustworthy Clinical Prediction Models</title>
  <dc:creator>Mark Zobeck</dc:creator>
  <link>https://www.thedoctorsdialectic.com/docs/posts/2025-01-25-modeling_philosophy/</link>
  <description><![CDATA[ 




<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.thedoctorsdialectic.com/docs/posts/2025-01-25-modeling_philosophy/modeling.png" class="preview-image img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Clinical prediction modeling, using data to predict patients’ clinical outcomes to improve medical decision-making, can be incredibly powerful if done well. Modern medicine is awash in unused data. Information that we can use to improve the lives of patients is everywhere if we just knew how to distill it from the muck and mire of the everyday chaos of clinical care. With it, we could:</p>
<ul>
<li><p>More efficiently diagnose diseases without patients suffering through tortuous journeys in the medical system, bouncing from doctor to doctor with no answers.</p></li>
<li><p>More accurately predict the prognosis of diseases, providing information about what the future will hold.</p></li>
<li><p>Make optimal medical decisions, enabling patients and physicians to wrestle with the risks and benefits of different treatment options to make the best decisions.</p></li>
<li><p>Confirm what we know to clarify what we don’t, accelerating progress in basic and translational science and identifying which clinical trials are actually worth doing.</p></li>
</ul>
<p>All of these benefits are within our reach, if only we could harness the ocean of data generated by the medical system every day to produce trustworthy and reliable clinical prediction models.</p>
</section>
<section id="unrealized-potential" class="level1">
<h1>Unrealized potential</h1>
<p>Classical methods of statistical prediction modeling for clinical applications have existed for decades, such as multivariable linear regression, logistic regression, ordinal regression, survival modeling, etc. There is a vast literature covering all of the relevant statistical and clinical aspects of developing such models, from sample size calculations and model performance to decision theory and implementation. The science of prediction modeling is very well developed.</p>
<p>Yet, these methods have not realized their potential. They have been used well for some applications and terribly for many others. Most models are optimized for publication and not for clinical use. They are developed to advance careers and not improve patient care. Even the good ones are rarely implemented into clinical practice. Running code in statistics software and writing a paper is vastly easier than changing clinical care. Despite a well-developed science of prediction modeling, the health system carries on largely ignorant of it.</p>
</section>
<section id="ai-has-made-the-situation-worse" class="level1">
<h1>AI has made the situation worse</h1>
<p>The rise of machine learning and AI has only worsened the situation. AI has demonstrated blockbuster results in certain use cases, such as for chatbots and applications in radiology and pathology. Yet, these do not translate well to clinical prediction tasks. AI is ravenous for data because it must train an incredible number of parameters. AI also craves stability in the system it is learning to reproduce. If the behavior of the system changes, the titanic algorithms struggles to adapt, like a massive ship that turns in a slow, wide arc. Clinical medicine is the opposite of this. Data are relatively sparse, and the underlying system that generates it is built on quicksand. Structural change is the rule rather than the exception. Moreover, the science of describing the reliability and trustworthiness of AI models is not well developed. The discipline is still grappling with key questions, such as causal inference methods and how to represent uncertainty when data are limited. AI methods that have produced headline success in some applications do not translate to the complex, dynamic, and messy world of clinical practice.</p>
</section>
<section id="useful-and-trustworthy-clinical-prediction-models" class="level1">
<h1>Useful and trustworthy clinical prediction models</h1>
<p>To realize clinical prediction modeling’s potential, we need a method for producing <u>useful</u> predictions that patients and providers can <u>trust</u>.</p>
<p><strong>Useful predictions:</strong></p>
<ul>
<li><p><em>Answer a specific and valuable question.</em> Sometimes, prediction models produce answers to different questions than the user has in mind. Other times, models are developed that answer a question that is not valuable because the information makes no difference either in terms of actions that people might take or psychological benefit from the knowledge it gives.</p></li>
<li><p><em>Support decisions</em>. People can use the predictions to decide what is the best next step. This process involves more than the predictions, such as utilities of outcomes and the context of actions. The output of the model should be readily usable by someone equipped with this information.</p></li>
<li><p><em>Can be implemented by the health system.</em> If the model demands too many resources, for example requiring data, IT infrastructure, or specialized expert knowledge that is unavailable, then it cannot practically be implemented. Models must be designed with constraints in mind.</p></li>
</ul>
<p><strong>Trustworthy predictions:</strong></p>
<ul>
<li><p><em>Provide the right kind of answers</em>. Predictions can be in the form of discrete categories or probabilities. The question it answers and the decisions it supports determine the best type of answer. The wrong type of answer can produce worse decisions.</p></li>
<li><p><em>Are accurate.</em> They generally answer the modeling question correctly. This can be demonstrated by measures of overall model performance, discrimination (how well the model separates groups) and calibration (whether the value or probability of an outcome matches the observed values/probabilities).</p></li>
<li><p><em>Have quantifiable uncertainty.</em> One can say that both the chance of getting heads on a coin toss and the chance of team winning a match for a sport you have never heard of and know nothing about is 50%, but you would be very certain about that statement for the coin and very uncertain for the sports team. That certainty matters as you make a decision, monitor results, and consider changing your mind about the right course of action. It also matters for whether or not the predictions can be improved my more work on the model.</p></li>
<li><p><em>Are not overfit to the data.</em> Models can be too good at predicting the dataset that is used to train it. They will fall apart when making predictions with new data. Methods for internal validation during model development must be used to demonstrate that the performance remains acceptable when simulating its use on new datasets.</p></li>
<li><p><em>Perform acceptably over time.</em> The dynamics of the health system that produce outcomes can change slowly or suddenly over time. Processes must be in place to monitor the model and respond when their performance degrades.</p></li>
<li><p><em>Perform acceptably in new situations</em>. Model performance can vary tremendously when used in new situations, such as in different hospitals or different types of patients. The predictions must be shown to be trustworthy in new settings.</p></li>
</ul>
<p>This is the path to developing valuable prediction modeling that help patients. These are the minimal criteria. Yet classical models and ML/AI can fail spectacularly at these points.</p>
<p>The path for ML/AI is more difficult than for the classical methods because implementation in the health system, providing the right kinds of answers, quantifying uncertainty, and not overfitting given the amount of available data are all much greater challenges. Proponents of AI/ML argue that their models are more accurate. Even granting this point, which is debatable, the consequences of doing these things poorly tend to negate any benefit from improved accuracy.</p>
<p>Achieving all of these properties is difficult regardless of the approach. The time, effort, and money required to do this well generally outweighs the benefit that an academic gains from publishing an analysis and moving on to the next thing. The literature is filled with descriptions of models that are accurate when predicting from the training data but are otherwise useless and not worthy of anyone’s trust.</p>
</section>
<section id="to-the-future" class="level1">
<h1>To the future!</h1>
<p>None of these are my original thoughts. There are many, meany people who want to do this well and have rigorously worked through these ideas. These points have been articulated and systematized for the wider scientific community (<a href="https://www.tripod-statement.org/">the TRIPOD+AI statement and its associated references are a good starting place</a>). This post is my process of synthesizing these essential concepts for my own practice as both a physician and data scientist.</p>
<p>These points should guide the integration of prediction models into clinical practice, but they probably won’t. Or at least they will only partially. The publishing incentives to stop short of anything practical are too great. Hype is much more effective at selling to healthcare executives than a careful evaluation of how well a model performs. This is boring nerd stuff.</p>
<p>Yet, useful and trustworthy modeling can win because reality is unrelenting. Hype will come and go. Expensive AI products will be purchased and found to be useless. Cycles of boom and bust will roll on. Amidst the noise, the future will remain open. We won’t stop craving reliable predictions while we continuously proceed into the unknown. Useful and trustworthy models will demonstrate their virtues as time rolls on, and health systems will become better at recognizing their value and more capable or supporting their implementation. The opportunities are tremendous if only we can avoid the allure of short term payoffs and do the hard work of demonstrating that a model truly improves patient care.</p>


</section>

 ]]></description>
  <category>Clinical Prediction Models</category>
  <guid>https://www.thedoctorsdialectic.com/docs/posts/2025-01-25-modeling_philosophy/</guid>
  <pubDate>Tue, 21 Jan 2025 06:00:00 GMT</pubDate>
  <media:content url="https://www.thedoctorsdialectic.com/docs/posts/2025-01-25-modeling_philosophy/modeling.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>External Controls in Oncology Clinical Trials</title>
  <dc:creator>Mark Zobeck</dc:creator>
  <link>https://www.thedoctorsdialectic.com/docs/posts/2025-01-17-external_controls/</link>
  <description><![CDATA[ 




<p><img src="https://www.thedoctorsdialectic.com/docs/posts/2025-01-17-external_controls/modeling.png" class="preview-image img-fluid"></p>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>External controls are, for better or worse, common in pediatric oncology clinical trials. I don’t love them. They are dangerous. However, there are arguments in their favor. In this post, I’ll briefly discuss what historical controls are, when their use might be justified, and why they’re dangerous.</p>
</section>
<section id="what-are-external-controls" class="level2">
<h2 class="anchored" data-anchor-id="what-are-external-controls">What are external controls?</h2>
<p>The purpose of clinical trials is to evaluate the effect of a treatment in some population of patients. In a classic randomized clinical trial, patients who meet the study criteria are randomized to either receive the standard of care for their disease or a new treatment. The outcome between the two groups is compared, and due to the miracle of randomization, the treatment effect can be identified as the difference in the outcomes between the groups.</p>
<p>External controls are a group of patients not enrolled in a clinical trial but used as a comparison group for patients on a trial. The difference between the outcomes for the controls and the treatment group is taken as the effect of treatment, much like the comparison with the standard of care arm in a clinical trial. For valid comparisons, the control group should look as similar as possible to those that could have been enrolled in the trial. The group may be taken from a previous clinical trial, a patient registry, or other real-world data source. The key limitation of this design is that external controls do not benefit from the wonders of randomization, which makes bias a much greater danger when estimating the effect of treatment.</p>
</section>
<section id="why-we-might-use-external-controls" class="level2">
<h2 class="anchored" data-anchor-id="why-we-might-use-external-controls">Why we might use external controls</h2>
<p>External controls are generally used when trialists cannot or should not enroll a comparison group for ethical reasons or because the disease is so rare. Below is a table briefly explaining three reasons that might justifying using external controls. I wouldn’t go so far as to call these <em>good</em> reasons, but perhaps they are permissible <span class="citation" data-cites="marion_use_2023">(Marion and Althouse 2023)</span>.</p>
<section id="permissible-reasons" class="level3">
<h3 class="anchored" data-anchor-id="permissible-reasons">Permissible reasons</h3>
<table class="table-striped table-hover table">
<colgroup>
<col style="width: 100%">
</colgroup>
<tbody>
<tr class="odd">
<td><strong>When Randomization to Placebo is Unethical</strong><br> In condition has with well-established, effective treatments, then randomizing patients to receive a placebo would be unethical. If investigators wish to measure the effect compared to no treatment then they may opt for an external control.</td>
</tr>
<tr class="even">
<td><strong>Rare Disease Research</strong><br>Rare diseases make it difficult to recruit sufficient numbers of participants to meet the power requirements for a trial. External controls may be used to reduce the size of the trial.</td>
</tr>
<tr class="odd">
<td><strong>Severe Outcomes or Vulnerable Populations</strong><br> Randomization may be viewed as unacceptable for diseases with particularly severe outcomes (e.g.&nbsp;terminal illness) or that affect vulnerable populations (e.g.&nbsp;children) even if there is no standard of care.</td>
</tr>
</tbody>
</table>
<p><span class="citation" data-cites="collignon_implementing_2021">Collignon et al. (2021)</span> sums up the use cases for historical (external) controls in their conclusion:</p>
<blockquote class="blockquote">
<p>The use of historical controls, therefore, is better suited for cases of high unmet clinical need, where the disease course is well characterized and the primary endpoint is objective.</p>
</blockquote>
</section>
<section id="suspect-reasons" class="level3">
<h3 class="anchored" data-anchor-id="suspect-reasons">Suspect reasons</h3>
<p>There are also many suspicious reasons for using external control. One is that they reduce the time and costs associated with conducting a trial. The problem with this reasoning is that the savings may be minimal. Enrolling 200 patients in a trial compared to 400 patients does not reduce the budget by half, given the enormous fixed costs associated with designing and opening trials. No matter how many patients are enrolled, the trial may have to be run for the same time when outcomes are measured over years, as with survival in oncology trials. While external controls might suggest savings, the benefits are not as advertised.</p>
<p>More importantly, there is an enormous price to pay for the credibility of the trial’s results. Many sources of bias can confound the treatment effect and make clear conclusions impossible. A trial may go on for ten years only to end in a collective, scientific shrug ¯\_(ツ)_/¯.</p>
</section>
</section>
<section id="sources-of-bias-from-external-controls" class="level2">
<h2 class="anchored" data-anchor-id="sources-of-bias-from-external-controls">Sources of bias from external controls</h2>
<p>External control’s fundamental problem is that they are not randomized, leaving many ways that they can introduce bias into the analysis. Randomization reveals a treatment effect by guaranteeing that only random chance determines which treatment patients receive. This ensures no residual confounding between treatment and the outcome of interest. In the parlance of directed acyclic graphs (DAGs), randomization erases all back door paths between the treatment and the outcome. No such guarantees exist for external controls, and backdoor paths very likely exist between treatment and outcomes. I’ve drawn the DAG below to represent the essential structure of the problem. There are many other more complex structures, but I find this to be a sufficient representation of the basic concerns.</p>
<div class="cell">
<div class="cell-output-display">
<div id="htmlwidget-a04bebed472442aa4158" style="width:100%;height:193px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-a04bebed472442aa4158">{"x":{"diagram":"\n  digraph mrdag {\n    graph [rankdir=TB]\n\n    # Node definitions\n    node [shape=ellipse]\n    U [label=\"Patient Group\"]\n    X [label=\"Treatment\"]\n    Y [label=\"Outcome\"]\n    { rank = same; X Y }\n\n    # Edges\n    U -> X\n    U -> Y\n    X -> Y [minlen=3]\n  }\n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<p>One example of how patient groups could affect treatment and outcome is if the external control group is drawn from a registry of sicker and older patients who tend to have worse outcomes than the group in the trial that received the treatment. This situation could make the treatment appear more effective than it truly is. There are many other sources of bias. The table below [adapted from <span class="citation" data-cites="burger_use_2021">(Burger et al. 2021)</span>], lists some of the main sources of bias and how to mitigate their effect.</p>
<section id="bias-types" class="level3">
<h3 class="anchored" data-anchor-id="bias-types">Bias types</h3>
<table class="table-striped table-hover table">
<colgroup>
<col style="width: 37%">
<col style="width: 62%">
</colgroup>
<thead>
<tr class="header">
<th>Type of Bias and Description</th>
<th>Mitigation Strategy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Selection Bias</strong><br>Clinical trial participants often have different characteristics compared to patients in routine care settings</td>
<td>• Design trial eligibility criteria that can be clearly applied to real-world settings<br>• When selecting external controls, carefully match population characteristics<br>• Use statistical approaches like propensity scoring, inverse probability weighting, or g-computation to account for population differences</td>
</tr>
<tr class="even">
<td><strong>Calendar Time Bias</strong><br>Treatment outcomes can vary across different time periods due to evolution in medical practices</td>
<td>• Select control patients from similar time periods as the trial<br>• Provide evidence that standard of care has remained stable<br>• If using historical controls, document stability of outcomes over relevant time periods</td>
</tr>
<tr class="odd">
<td><strong>Regional Bias</strong><br>Patient outcomes may differ between geographical locations due to variations in healthcare delivery</td>
<td>• Source control patients from comparable geographic regions<br>• Document that care standards are similar across regions<br>• If using different regions, demonstrate comparable outcome patterns</td>
</tr>
<tr class="even">
<td><strong>Assessment Bias</strong><br>Knowledge of treatment assignment can influence how outcomes are evaluated</td>
<td>• Focus on objective endpoints where possible<br>• Consider independent outcome review processes<br>• Implement rigorous sensitivity analyses</td>
</tr>
<tr class="odd">
<td><strong>Different Endpoint Bias</strong><br>Clinical trial endpoints may be measured differently than in routine practice</td>
<td>• Ensure consistent endpoint definitions<br>• Obtain necessary documentation (e.g., imaging) to allow standardized assessments<br>• Account for differences in assessment frequency</td>
</tr>
<tr class="even">
<td><strong>Immortal Time Bias</strong><br>Challenges in establishing comparable time zero points between trial and control patients</td>
<td>• Clearly define and align study entry time points<br>• Carefully evaluate potential biases in time-based analyses</td>
</tr>
<tr class="odd">
<td><strong>Retrospective Selection Bias</strong><br>Risk of selectively choosing external data or analysis approaches after seeing results</td>
<td>• Pre-specify all selection criteria and analyses<br>• Document selection process transparently</td>
</tr>
<tr class="even">
<td><strong>Study Bias</strong><br>Trial participation itself can affect outcomes due to different care patterns</td>
<td>• Consider selecting controls from similar clinical settings<br>• Document and account for differences in care delivery</td>
</tr>
<tr class="odd">
<td><strong>Between Study Variability</strong><br>High unexplained outcome variation across studies suggests presence of important uncontrolled factors</td>
<td>• Consider randomized design if high unexplained variability exists<br>• Carefully document and account for known sources of variation</td>
</tr>
<tr class="even">
<td><strong>Intercurrent Event Bias</strong><br>Events occurring after study entry can affect comparability</td>
<td>• Apply consistent approaches to handling intercurrent events<br>• Consider multiple analytical approaches to test robustness</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="how-to-reduce-bias-when-using-external-controls" class="level2">
<h2 class="anchored" data-anchor-id="how-to-reduce-bias-when-using-external-controls">How to reduce bias when using external controls</h2>
<p>The best way to reduce bias from external controls is an open area of research. This is a polite way of saying it’s complicated and a mess. It’s complicated because these studies are not quite observational studies, but they definitely aren’t randomized trials. Researchers have, therefore, opted for a range of analytical techniques, including using thresholds, propensity scores, matching, and meta-analytic methods. A full discussion of analytical options is outside the scope of this blog post, but see the references at the end for more. Regardless of the method used, the most important way to control bias is undoubtedly to select an external control group that is a close comparison to the types of patients enrolled in the trial.</p>
<p>Analyzing data from these types of studies is also a mess because many untoward motivations can sneak into the results. These studies can be used to justify regulatory approval for a drug or biomedical device. Companies are motivated to represent their product in the best way possible because there is a pot of gold at the end of the quest for regulatory approval. Mixing a company’s profit margins with a high dimensional vector of bias sources and a flexible choice of analytical techniques is a recipe for chaos.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>I think it’s possible to justify the use of external controls and glean useful information from them in certain settings. Regulators have even begun to admit them as evidence to justifty drug approval [see <span class="citation" data-cites="mishra-kalyani_external_2022">(Mishra-Kalyani et al. 2022)</span> for examples]. But I also think it’s a generally rational policy to increase one’s skepticism about a study in proportion to the number of free researcher degrees of freedom with an additional adjustment for the presence of motivated reasoning. Both are present in abundance with external controls. So, it makes good sense to bring a strong scientific skepticism to these studies. In this blog, we’ve outlined the many ways that bias influences their results. The burden of proof – a rightfully heavy one – should rest on the investigators to demonstrate their study design and analysis overcome the many limitations of external controls.</p>
</section>
<section id="references" class="level2">




</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-burger_use_2021" class="csl-entry">
Burger, Hans Ulrich, Christoph Gerlinger, Chris Harbron, Armin Koch, Martin Posch, Justine Rochon, and Anja Schiel. 2021. <span>“The Use of External Controls: To What Extent Can It Currently Be Recommended?”</span> <em>Pharmaceutical Statistics</em> 20 (6): 1002–16. <a href="https://doi.org/10.1002/pst.2120">https://doi.org/10.1002/pst.2120</a>.
</div>
<div id="ref-collignon_implementing_2021" class="csl-entry">
Collignon, Olivier, Anna Schritz, Riccardo Spezia, and Stephen J. Senn. 2021. <span>“Implementing Historical Controls in Oncology Trials.”</span> <em>The Oncologist</em> 26 (5): e859–62. <a href="https://doi.org/10.1002/onco.13696">https://doi.org/10.1002/onco.13696</a>.
</div>
<div id="ref-marion_use_2023" class="csl-entry">
Marion, Joe D., and Andrew D. Althouse. 2023. <span>“The Use of Historical Controls in Clinical Trials.”</span> <em><span>JAMA</span></em> 330 (15): 1484–85. <a href="https://doi.org/10.1001/jama.2023.16182">https://doi.org/10.1001/jama.2023.16182</a>.
</div>
<div id="ref-mishra-kalyani_external_2022" class="csl-entry">
Mishra-Kalyani, P. S., L. Amiri Kordestani, D. R. Rivera, H. Singh, A. Ibrahim, R. A. DeClaro, Y. Shen, et al. 2022. <span>“External Control Arms in Oncology: Current Use and Future Directions.”</span> <em>Annals of Oncology</em> 33 (4): 376–83. <a href="https://doi.org/10.1016/j.annonc.2021.12.015">https://doi.org/10.1016/j.annonc.2021.12.015</a>.
</div>
</div></section></div> ]]></description>
  <category>Causation &amp; Clinical Trials</category>
  <guid>https://www.thedoctorsdialectic.com/docs/posts/2025-01-17-external_controls/</guid>
  <pubDate>Fri, 17 Jan 2025 06:00:00 GMT</pubDate>
  <media:content url="https://www.thedoctorsdialectic.com/docs/posts/2025-01-17-external_controls/modeling.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Gratitude reduces the complexity of modern life to make it more meaningful</title>
  <dc:creator>Mark Zobeck</dc:creator>
  <link>https://www.thedoctorsdialectic.com/docs/posts/2024-01-01-gratitude/</link>
  <description><![CDATA[ 




<p><img src="https://www.thedoctorsdialectic.com/docs/posts/2024-01-01-gratitude/coffee-chillin.png" class="preview-image img-fluid"></p>
<section id="the-contentification-of-life" class="level2">
<h2 class="anchored" data-anchor-id="the-contentification-of-life"><strong>The contentification of life</strong></h2>
<p>The world is increasingly filled with noise and nonsense, making it difficult to see what is valuable amid a torrent of trivialities. With the rise of social media, our attention has become an economic commodity. Four million new posts are made on Instagram every hour; 3.7 million new YouTube videos are uploaded every day. This is chump change compared to what’s coming. The rate of content production is going to increase exponentially as generative AI matures in consumer applications. And the contentification of the internet for the commodification of our attention has overflowed into the offline world. Everywhere we turn, we’re offered the chance to level up in our jobs, our relationships, our skills, or our goals (and on Facebook, for me, level up my hip mobility because I clicked on an ad about stretching once). There’s always more to see, more to learn, and more to do to maximize the moment and optimize our happiness. Almost all of this is a heap of rubbish. Yet there are always small, buried treasures that keep us coming back to rummage through the garbage.</p>
</section>
<section id="the-exponentiation-of-life" class="level2">
<h2 class="anchored" data-anchor-id="the-exponentiation-of-life"><strong>The exponentiation of life</strong></h2>
<p>Beyond the value of the content we produce, the speed of production also gives us heartburn. We humans, evolved in the cradle of the natural numbers, nourished as a species by the small positive integers that we found on our fingers and our toes, have difficulty handling the exponentiation of possible human experiences. There are so many things we could do. So many ways to spend our time. So many counterfactual worlds unfolding at ever increasing speeds ahead of us. Navigating life is increasingly complex, increasingly overwhelming. Our attention can’t handle it all.</p>
</section>
<section id="many-options-that-mostly-stink" class="level2">
<h2 class="anchored" data-anchor-id="many-options-that-mostly-stink"><strong>Many options that mostly stink</strong></h2>
<p>So, we have tons of ways we could spend our time, energy, and attention. Too many. Most of these options are garbage. But it’s hard to tell upfront what is worthless and what is valuable because attention is money, so everything is marketing. Everything has a new coat of paint and has been spritzed with perfume. What do we do when there are so many things we could do, but it’s hard to tell which are wastes of time? How do we reduce the dimensionality of our options with so much noisy data?</p>
</section>
<section id="gratitude-can-help" class="level2">
<h2 class="anchored" data-anchor-id="gratitude-can-help"><strong>Gratitude can help</strong></h2>
<p>Gratitude can help us focus on what is valuable. Being grateful for something implies a host of magnificent and healthy epistemic processes. For example, I’m grateful for my dog, Rosie. I’m particularly grateful that she’s acting less like a puppy and more like a productive member of my family’s household society. To tell you about my gratitude for my dog’s behavior, I had to first search through all sorts of things in my life I could tell you about. Rosie was easy to find in this search process. However the algorithm works, it was efficient and accurate - it didn’t take me long to come up with an example and I’m certain about my feeling here. To articulate my gratitude, I then had to particularize Rosie as an object of my attention. Rosie is not an abstract concept or just an idea. She became an object of my attention with properties and characteristics that I can describe. In other words, I focused on her to the exclusion of anything else. Once presented in my awareness, my relationship with her takes center stage. I’m grateful for her because of how we interact. Not just because of who she is or who I am but because of who we are together. We’re correlated statistically. What I think is associated with who she is. We’re coupled cybernetically. How she exists influences what I do. My gratitude is about our existence together - a dynamic, fluid, abstract-yet-influential relationship that helps to direct my experiences and actions over time.</p>
</section>
<section id="gratitude-as-a-signal-of-value" class="level2">
<h2 class="anchored" data-anchor-id="gratitude-as-a-signal-of-value"><strong>Gratitude as a signal of value</strong></h2>
<p>Rosie has helped me find what is valuable. My gratitude acted as both search and filter for finding something that has meaning to me. Easy, quick, accurate. It doesn’t matter how many more things I add to search through or how much more content humanity produces; it will still be easy to identify her - and a host of other good things in my life - as something I’m grateful for. This salience in my focus, this worthiness of attention that gratitude produces, is something I can only describe as meaningful. It fills that epistemic moment with a sense of value. Gratitude helps us find the signals of value in the noise of modern life.</p>
</section>
<section id="gratitude-as-dimensionality-reduction" class="level2">
<h2 class="anchored" data-anchor-id="gratitude-as-dimensionality-reduction"><strong>Gratitude as dimensionality reduction</strong></h2>
<p>To be grateful for Rosie, I also had to focus on her to the exclusion of anything else. There are many, perhaps uncountably infinite, things I could be grateful for. There are also many, perhaps uncountably infinite, ways that I could be grateful for Rosie. Relationships are dynamic. They change in quality over time. But from all of these possibilities, I could wrap my attention around a thing known as Rosie and describe her in a way that is comprehensible to you in just a few words. I could envelop the intricate complexities of our relationship, an immaterial thing, to communicate the positive experience I take from it. Considering how Rosie and I can move through life together, there are yet infinitely more ways that we could act and interact, and yet my gratitude at where we’ve been suggests possible futures that are valuable and that would make me grateful anew. In a sea of infinite options, gratitude has reduced the dimensions I must consider, helping me reflect on where I’ve been and chart a course for the future.</p>
</section>
<section id="gratitude-in-2024" class="level2">
<h2 class="anchored" data-anchor-id="gratitude-in-2024"><strong>Gratitude in 2024</strong></h2>
<p>This has been a meditation on part of life I find overwhelming. I want to do good stuff. I want to be good at the things I do. I want to have meaningful relationships. I want to live my life well. Many and more are the ways this could happen or could go wrong. There are so many dang options for how to spend my time. I’m extremely grateful for my dog, obviously, as well as my family, friends, job, and God. Gratitude helps me slow down, find those things that are meaningful, and savor the good dynamics of those relationships. It also helps me to think about how to nourish those good things so they bloom into something beautiful. Being grateful for what I’ve experienced in 2023 helps me plan what to do in 2024. I have goals, but gratitude suggests the purpose of planning isn’t to achieve goals but to help what is true, beautiful, and good in my life flourish.</p>


</section>

 ]]></description>
  <category>Musings &amp; Meditations</category>
  <guid>https://www.thedoctorsdialectic.com/docs/posts/2024-01-01-gratitude/</guid>
  <pubDate>Mon, 01 Jan 2024 06:00:00 GMT</pubDate>
  <media:content url="https://www.thedoctorsdialectic.com/docs/posts/2024-01-01-gratitude/coffee-chillin.png" medium="image" type="image/png" height="82" width="144"/>
</item>
<item>
  <title>The Epistemic Arc - a conceptual map about how to learn from data in the presence of uncertainty</title>
  <dc:creator>Mark Zobeck</dc:creator>
  <link>https://www.thedoctorsdialectic.com/docs/posts/2022-06-04-epistemic-arc-intro/index.en.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Learning from data is hard.</p>
<p><strong>The world is full of noise and nonsense masquerading as “insights” from data analyses.</strong></p>
<p>If its so easy to go wrong, how can we reliably learn from data and avoid the many common analytical shenanigans that can ruin our results?</p>
<p>I recently <a href="https://hbiostat.regfox.com/rms2022-video-course">purchased and watched</a> the videos for <a href="https://twitter.com/f2harrell?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor">Frank Harrell</a>’s incredible statistics short course, <a href="https://hbiostat.org/rms/"><strong>Regression Modeling Strategies</strong></a>(for the more advanced stats enthusiasts, this course outlines an <em>incredible</em> method for principled statistical analyses). As part of the course, <a href="https://twitter.com/DrewLevy">Drew Levy</a> gave a wonderful presentation about <a href="https://hbiostat.org/doc/rms/causalModels.pdf">model selection using causal models</a>, and, almost as an aside, he included a graphic about his framework for how he conceptualizes analyses of observational data.</p>
<p>I was struck by the elegance of his framework. It concisely summarizes the steps in the learning process and identifies the many danger zones that can ruin your learning (<a href="https://sites.google.com/dogoodscience.com/home">click here to read more from Drew Levy’s website</a>). It functions as a great conceptual roadmap for how to reliably learn from data while avoiding analytical shenanigans</p>
<p>In this post, I will adapt and expand the framework to explain how it provides a unified roadmap for learning from data. This framework is flexible and applies just as well to observational epidemiological studies as to randomized trials, physical experiments, any other branch of science, and even in our daily lives.</p>
<p>This will be a high level overview. In future posts, I will explore specific danger zones in more detail. Beyond organizing important statistical principals, this framework has important philosophical and psychological consequences. I also aspire to explore theses areas more in future posts.</p>
</section>
<section id="the-epistemic-arc" class="level2">
<h2 class="anchored" data-anchor-id="the-epistemic-arc">The Epistemic Arc</h2>
<p><img src="https://www.thedoctorsdialectic.com/docs/posts/2022-06-04-epistemic-arc-intro/cover_expanded-epistemic_arc-wireframe.png" class="img-fluid"></p>
<p>The above figure depicts the <strong>Epistemic Arc</strong>, which describes the process that anyone must follow when learning from data in the presence of uncertainty.</p>
<p>The first highlight is that there is a main character to this story: <strong>you</strong>. You are the hero or heroine of this epistemic adventure! You are a player on the statistical stage. You are an inseparable part of the learning process. You are the <strong>Learner</strong>.</p>
<p>Each box represents a specific <strong>object</strong> that is required for the learning process (a noun). Each arrow depicts a <strong>step</strong> that must be performed to move from one object to the next (a verb). Let’s zoom in on each step to define the objects involved and the actions performed during it.</p>
<section id="step-1.-nature---population" class="level3">
<h3 class="anchored" data-anchor-id="step-1.-nature---population">Step 1. Nature -&gt; Population</h3>
<p><img src="https://www.thedoctorsdialectic.com/docs/posts/2022-06-04-epistemic-arc-intro/step1-nature-population.png" class="img-fluid"></p>
<section id="definitions" class="level4">
<h4 class="anchored" data-anchor-id="definitions">Definitions</h4>
<p><strong>Step 1:</strong> The process of nature or a physical process producing a population or system the Learner wishes to learn more about.</p>
<p><strong>Nature or Physical Process:</strong> I define nature as whatever physical stuff exists upon which the drama of physical reality unfolds. Nature is the generator of the physical world the Learner encounters and wishes to know more about. A physical process is a mechanistic derivative of nature, perhaps built by humans, that may itself produce interesting phenomena to learn about. Examples: Nature - quarks, neurons, cats, quasars; Physical process - factory that produces bowling pins, a pendulum swinging in a clock.</p>
<p><strong>Population or System:</strong> A population is a distinct collection of entities derived from nature that is interesting to the Learner. A system is a set of interacting entities carved out of the larger system of physical reality. Examples: Population - Orange cats in Austin, Texas, children with ADHD, all the weeds that grow between sidewalk cracks; System - trees that talk to each other using fungi, academic medical education, ATP synthesis in your body from the electron transport chain.</p>
</section>
<section id="explanation" class="level4">
<h4 class="anchored" data-anchor-id="explanation"><strong>Explanation</strong></h4>
<p><strong>Goal:</strong> The Learner identifies what he or she wishes to learn about either in nature or in a population or system that emerges from it. This is where the Learner formulates the questions to answer with data. (e.g.&nbsp;For the weed between sidewalk cracks example, perhaps the question is: which type of pesticide most effectively kills weeds between sidewalk cracks?)</p>
<p><strong>Caution:</strong> Note this is a <em>highly</em> philosophical step, even if it seems straightforward to the Learner. There are no <em>populations</em> or <em>systems</em> in nature. These are <em>concepts</em> that the Learner overlays onto nature. Why does this matter? Because we, the Learners, are making <em>analytical decisions</em> about the most fundamental elements in the epistemic arc by defining the population or system to study ourselves (What is the definition of a weed? What is a crack? What is a sidewalk? Does a driveway count? Where will study the weeds?).</p>
<p><strong>Beware:</strong> This step sets the entire trajectory of the epistemic arc the Learner will follow. Precise questions yield precise answers. Vague questions produce vacuous answers that can be stretched, misshapen, and filled with whatever meaning one desires. Squishy questions may help get publications, but we won’t be any closer to learning truth.</p>
<p><strong>Bonus:</strong> <a href="https://twitter.com/Lester_Domes">Sander Greenland</a> recently <a href="https://arxiv.org/pdf/2011.02677.pdf">argued</a> that the discipline of statistics has explicitly <em>causal</em> foundations. In his paper, he says, “Whether answering the most esoteric scientific questions or the most mundane administrative ones, and whether the question is descriptive, causal, or purely predictive, causal reasoning will be crucially involved (albeit often hidden to ill effect in equations and assumptions used to get the”results”). I think this is correct and this step demonstrates and contextualizes his argument.</p>
</section>
</section>
<section id="step-2.-population---sample" class="level3">
<h3 class="anchored" data-anchor-id="step-2.-population---sample">Step 2. Population -&gt; Sample</h3>
<p><img src="https://www.thedoctorsdialectic.com/docs/posts/2022-06-04-epistemic-arc-intro/step2-pop-sample.png" class="img-fluid"></p>
<section id="definitions-1" class="level4">
<h4 class="anchored" data-anchor-id="definitions-1">Definitions</h4>
<p><strong>Step 2:</strong> The process of <em>identifying</em> (no data collection yet) a sample that can be further scrutinized and <em>designing</em> a process that can deliver appropriate inferences about the population or the natural process that generates it from the data collected from the sample.</p>
<p><strong>Sample</strong> (noun): A subset of the population or a toy model of the system. These are the members of the population for whom the Leaner has the ability to collect data and directly learn from.</p>
</section>
<section id="explanation-1" class="level4">
<h4 class="anchored" data-anchor-id="explanation-1">Explanation</h4>
<p><strong>Goal:</strong> The goal is for the Learner to identify what sample will generate data that is most informative for the questions and then to design the process to learn from the data in a way that will account fo the limitations of using an imperfect sample to learn about a (possibly theoretical) population. In science, this is study design - e.g.&nbsp;does the Learner need to conduct an RCT, case-control study, cross-sectional study, etc.</p>
<p><strong>Caution:</strong> <em>Randomness</em> plays a big role in in our ability to learn about our population of interest from the sample. A <em>random</em> sample from the population as in a survey helps to ensure the sample is reflective of the population. A sample that is <em>randomized</em> to a treatment as in a randomized clinical trial helps to ensure what we learn about the causal process we are studying. Often randomness cannot be ensured at the level of the sample. In this case, study design and methods of causal inference help to make the sample reflects the population well enough to answer our question.</p>
<p><strong>Caution 2:</strong> Confusing terminology - to sample (verb) is one method of obtaining a sample (noun), but that’s only one way. Sometimes your sample is given to you, such as obtaining all medical records for a given disease from an electronic medical record. In this case you have a sample, a subset of a larger population (all patients with the disease), but you didn’t <em>sample</em> the population for it.</p>
<p><strong>Beware:</strong> Many crippling problems arise in this step even though you have not collected any data! <em>Selection bias</em> occurs when there’s a systematic reason your sample does not reflect your population. <em>Confounding</em> occurs when you choose a sample for whom data about an important feature of the sample that affects the relationship between the treatment/exposure and the outcome will be unavailable or uncollected. If your analysis does not have data about this feature, then what you learn could be systematically different than the truth.</p>
<p><strong>Bonus:</strong> <a href="https://www.jclinepi.com/action/showPdf?pii=S0895-4356%2821%2900240-7">Directed acyclic graphs</a> (<a href="https://www.edx.org/course/causal-diagrams-draw-your-assumptions-before-your">DAGs</a>) are a great way to graphically encode relevant information about the casual system, population, and sample from steps 1 and 2. I recommend their development in this step. DAGs can display not just confounding, but also <a href="https://pubmed.ncbi.nlm.nih.gov/15308962/">selection bias</a> (and <a href="https://pubmed.ncbi.nlm.nih.gov/28535177/">here</a>) and many other design considerations.</p>
</section>
<section id="step-3.-sample---data" class="level4">
<h4 class="anchored" data-anchor-id="step-3.-sample---data">Step 3. Sample -&gt; Data</h4>
<p><img src="https://www.thedoctorsdialectic.com/docs/posts/2022-06-04-epistemic-arc-intro/step3-sample-data.png" class="img-fluid"></p>
</section>
<section id="definitions-2" class="level4">
<h4 class="anchored" data-anchor-id="definitions-2">Definitions</h4>
<p><strong>Step 3:</strong> The process of measuring features of the sample (i.e.&nbsp;collect data).</p>
<p><strong>Data</strong>: A collection of measurements of variables (features) that describe different interesting aspects of the sample.</p>
</section>
<section id="explanation-2" class="level4">
<h4 class="anchored" data-anchor-id="explanation-2">Explanation</h4>
<p><strong>Goal:</strong> The Learner measures values of the variables accurately!</p>
<p><strong>Caution:</strong> <em>Which</em> variables are measured matters both because of the potential for confounding as discussed in step 2, as well as the potential to induce <em>collider bias</em> that could emerge in step 5. <em>How</em> variables are measured also matters. For example, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1458573/">continuous variables contain much more information than binary variables</a>, so if the Learner chooses to classify a continuous variable as a binary variable (e.g.&nbsp;blood pressure as high or low instead of the systolic/diastolic measurements), then <a href="https://www.fharrell.com/post/ordinal-info/">the Learner loses information</a> before any analysis has been performed.</p>
<p><strong>Beware:</strong> More crippling problems arise here. <a href="https://jech.bmj.com/content/58/8/635.long">Measurement error</a> refers to different ways of inaccurately collecting or recording data (e.g.&nbsp;measuring blood pressure in a screaming 3-year-old will not be accurate). <a href="https://jech.bmj.com/content/58/8/635.long">Information biases</a> are a related and overlapping group of problems that occur during the conduct of the study that will make the analysis inaccurate. Incomplete or <a href="https://www.youtube.com/watch?v=oMiSb8GKR0o">missing data</a> can ruin an otherwise well designed study. <a href="https://statmodeling.stat.columbia.edu/2019/09/13/deterministic-thinking-dichotomania/">Dichotomania</a> (as discussed in the caution) can be so damaging that it prevent the Learner from answering his or her question when they would have been able to if the variables were measured as continuous or ordinal.</p>
</section>
</section>
<section id="step-4.-data---analysis" class="level3">
<h3 class="anchored" data-anchor-id="step-4.-data---analysis">Step 4. Data -&gt; Analysis</h3>
<p><img src="https://www.thedoctorsdialectic.com/docs/posts/2022-06-04-epistemic-arc-intro/step4-data-analysis.png" class="img-fluid"></p>
<section id="definitions-3" class="level4">
<h4 class="anchored" data-anchor-id="definitions-3">Definitions</h4>
<p><strong>Step 4:</strong> The process of wrangling and transforming the raw data into a format that can be fed into an analysis.</p>
<p><strong>Analysis:</strong> The method that will be used to answer the question (in the next step) comprised of the transformed data, the relationships between the data (e.g.&nbsp;which is a predictor and which is the outcome variable), and the mathematical and algorithmic machinery that will perform the computational operations.</p>
</section>
<section id="explanation-3" class="level4">
<h4 class="anchored" data-anchor-id="explanation-3"><strong>Explanation</strong></h4>
<p><strong>Goal:</strong> The Learner transforms the data accurately and in a way that maximally preserves information so that it can be analyzed.</p>
<p><strong>Caution:</strong> <em>How</em> data are transformed matters, just like how they are measured matters. If a variable is measured as continuous and than transformed into a binary variable, that will harm the analysis. Also, many errors are induced in this step because of disorganization, clumsy human hands, and non-reproducible data management. <a href="https://open-science-training-handbook.gitbook.io/book/open-science-basics/reproducible-research-and-data-analysis">Reproducible research methods</a> are very practical and very valuable for preventing these errors.</p>
<p><strong>Beware:</strong> Dichotomania can crop up again here! Also, if you happen upon an interesting data set, it is very tempting to <em>start</em> at this step. This is a fatal mistake. Many of the concerns we’ve discussed (e.g.&nbsp;selection bias, confounding, measurement error) occur before or during data generation. Steps 1-3 always proceed step 4, no matter how big is your data or how fancy is your machine learning technique, and if you are unsure of the quality of steps 1-3, consider step 4 fatally compromised.</p>
</section>
</section>
<section id="step-5.-analysis---inference" class="level3">
<h3 class="anchored" data-anchor-id="step-5.-analysis---inference">Step 5. Analysis -&gt; Inference</h3>
<p><img src="https://www.thedoctorsdialectic.com/docs/posts/2022-06-04-epistemic-arc-intro/step5-analysis-inference.png" class="img-fluid"></p>
<section id="definitions-4" class="level4">
<h4 class="anchored" data-anchor-id="definitions-4">Definitions</h4>
<p><strong>Step 5:</strong> The process of conducting the analysis and answering the question using the data collected from the sample.</p>
<p><strong>Inference or Prediction:</strong> Inference is the result of using data from the sample to learn about the population or system of interest. Prediction is using the data from the sample to understand what may be true about the population in the future. These are generally perceived as separate but related learning tasks, and the Learner’s goal may only be one or the other.</p>
</section>
<section id="explanation-4" class="level4">
<h4 class="anchored" data-anchor-id="explanation-4">Explanation</h4>
<p><strong>Goal:</strong> The Learner conducts the analysis to produce inferences or predictions that he or she will use to answer the question.</p>
<p><strong>Caution:</strong> This is where technical statistical and mathematical considerations dominate. Whole PhD theses are written over very specific technical details in this step. Let the Learner be careful and seek appropriate technical support.</p>
<p><strong>Beware:</strong> Due to the technical nature of this step, many sneaky risks lurk here. Model assumptions, model specification, and model selection refer to the process of developing statistical models that reflect in math the most important concepts required to answer the question. The <a href="https://www.youtube.com/watch?v=EuBBz3bI-aA&amp;vl=en">bias-variance</a> trade off is an important decision about how flexible a model should be to reflect the observed data. P-hacking and <a href="https://www.americanscientist.org/article/the-statistical-crisis-in-science">researchers degrees of freedom</a>/<a href="http://www.stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf">garden of forking paths</a> are all non-mathematical methods of massaging the data (intentionally or unintentionally) to get an interesting or publishable result (<a href="https://www.fharrell.com/post/improve-research/">here is a blog post that discusses many of the preceding points</a>). Also this is where you can <em>induce</em> bias by adding variables into your analysis, called <a href="https://jamanetwork.com/journals/jama/fullarticle/2790247#:~:text=Collider%20bias%20occurs%20when%20an,that%20is%20not%20controlled%20for."><em>collider bias</em></a>(<a href="https://getyarn.io/yarn-clip/ba49f8a3-0945-4a7b-b991-ca652b72a921/gif">are you frightened?</a>). Analysis workflows (Bayesian workflows <a href="https://arxiv.org/abs/2011.01808">here</a>, and <a href="https://www.nature.com/articles/s43586-020-00001-2.pdf">here</a>, <a href="https://hbiostat.org/doc/rms.pdf">RMS workflow</a> - chapter 4, particularly 4.12 - and <a href="http://hbiostat.org/rflow/">here</a>) can help guide you safely through this treacherous valley of death and deceit.</p>
</section>
</section>
<section id="step-6.-inference---decision" class="level3">
<h3 class="anchored" data-anchor-id="step-6.-inference---decision">Step 6. Inference -&gt; Decision</h3>
<p><img src="https://www.thedoctorsdialectic.com/docs/posts/2022-06-04-epistemic-arc-intro/step6-inference-decision.png" class="img-fluid"></p>
<section id="definitions-5" class="level4">
<h4 class="anchored" data-anchor-id="definitions-5">Definitions</h4>
<p><strong>Step 6.</strong> The process of using the inference along with other information that the Learner knows to draw conclusions about the question and then decide how to act given what has been learned.</p>
<p><strong>Decision &amp; Action</strong>: These are the decisions and actions that result from what was learned. These are the answers to the questions “now what do I do with what I learned?”</p>
</section>
<section id="explanation-5" class="level4">
<h4 class="anchored" data-anchor-id="explanation-5"><strong>Explanation</strong></h4>
<p><strong>Goal:</strong> The Learner considers the inferences or predictions that result from the analysis against other information that the Learner knows (i.e.&nbsp;the results of many other epistemic arcs) and against the costs and benefits of different outcomes of decisions to decide what to is the best course of action based on the new knowledge.</p>
<p><strong>Caution:</strong> Inferences and predictions are not decisions. These are <em>very</em> different concepts that are often conflated together. Their conflation leaves out two crucial elements. One is that that you, the Leaner, bring many other learned things to this step (I conceptualize it as the intersection of many intersecting epistemic arcs). This additional information is relevant for decision making. The second is that costs and benefits from outcomes of decisions are nowhere reflected in <em>this</em> learning process (they also require their own epistemic arcs!; <a href="https://www.fharrell.com/post/dca/">this blog gives a helpful primer on decision curve analysis</a>).</p>
<p><strong>Beware:</strong> This is where human psychology with all of its frailty and biases can dominate. We all can fall prey to confirmation bias and <a href="https://thedecisionlab.com/biases">many other cognitive biases</a>, to motivated reasoning, and to dishonest reasoning. The consequence of us being an inseparable part of the learning process is that we bring our psychological and moral baggage along with us :/</p>
</section>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p><a href="https://www.thedoctorsdialectic.com/2022/06/04/epistemic-arc-intro/explanations_and_expanded-epistemic_arc-wireframe.png"><img src="https://www.thedoctorsdialectic.com/docs/posts/2022-06-04-epistemic-arc-intro/explanations_and_expanded-epistemic_arc-wireframe.png" class="img-fluid"></a></p>
<p>Step by step, we’ve walked along the Epistemic Arc to learn from data in the presence of uncertainty. Along the way, we’ve noted some areas where we must use caution and many explosive areas we must navigate with extreme care. We’ve also seen how the Learner is not only the primary agent doing the learning, but also a necessary actor in the learning process. <strong>The Epistemic Arc unifies these disparate philosophical, psychological, and statistical concepts into a single framework that we can use as a roadmap to conduct principled data analysis and avoid producing noise and nonsense that masquerade as “insights”.</strong></p>


</section>

 ]]></description>
  <category>Statistics &amp; Heuristics</category>
  <guid>https://www.thedoctorsdialectic.com/docs/posts/2022-06-04-epistemic-arc-intro/index.en.html</guid>
  <pubDate>Sat, 04 Jun 2022 05:00:00 GMT</pubDate>
  <media:content url="https://www.thedoctorsdialectic.com/docs/posts/2022-06-04-epistemic-arc-intro/cover_expanded-epistemic_arc-wireframe.png" medium="image" type="image/png" height="66" width="144"/>
</item>
<item>
  <title>Pediatric cancer treatment abandonment: a tragic but preventable event</title>
  <dc:creator>Mark Zobeck</dc:creator>
  <link>https://www.thedoctorsdialectic.com/docs/posts/2022-04-10-pediatric_abandonment/index.en.html</link>
  <description><![CDATA[ 




<p><strong>A tragic reality</strong> that pediatric oncology providers in resource-constrained commonly encounter: after a child with cancer starts treatment, many families leave and never return for care.</p>
<p>The global oncology community has given this event a specific label: <em>treatment abandonment</em>.</p>
<p>To explain why treatment abandonment happens and how to prevent it, let me tell you a story. The narrative is fictional, but it is based on the common experiences that families report while their child is undergoing cancer treatment.</p>
<p><strong>Pablo was a five-year-old boy who lived with his mom and two younger sisters in a rural village in Central America.</strong></p>
<p>He liked to do things most little boys like to do – kick a ball around in the street, chase his sisters with bugs, and help his mom care for their chickens. One day he developed a fever and became very pale. Over the next two weeks, the fevers didn’t stop, so his mom took him to the clinic in his village, where he saw a nurse who decided to send them for blood tests at the nearest hospital.</p>
<p>It was two days before his mom could secure a ride to make the normally two-hour journey to the hospital that took four hours because rain turned the dirt roads leading out of the village to mud. Workers at the hospital took blood from Pablo and after a few hours, a somber-looking doctor told his mom the bad news.</p>
<section id="the-doctor-was-concerned-pablo-had-a-life-threatening-blood-cancer-called-leukemia." class="level3">
<h3 class="anchored" data-anchor-id="the-doctor-was-concerned-pablo-had-a-life-threatening-blood-cancer-called-leukemia."><strong>The doctor was concerned Pablo had a life-threatening blood cancer called “leukemia”.</strong></h3>
<p>Pablo’s mom had a 3rd-grade education. She primarily spoke the indigenous language of her village and was merely conversational in Spanish, her doctor’s primary language. The doctor spent an hour talking to her about many things, much of which she didn’t understand. She knew her son had a disease in his blood, and she knew it was life-threatening, but she still wasn’t clear how he got it and feared negative spiritual forces were at work.</p>
<p>The doctors started treatment in the hospital, and after a few days, Pablo started looking much better, almost back to normal. He was discharged from the hospital and told he had appointments to come back every week for the next several months. Their family had government insurance that covered part of the hospital stay, but they would still have to pay the costs of travel, food, and lodging for every visit.</p>
<p>Pablo’s aunt and uncle lived in the city where the hospital was located.</p>
</section>
<section id="pablo-and-his-mom-moved-in-with-his-aunt-and-uncle-their-4-kids-2-dogs-and-a-coop-full-of-chickens-to-save-money." class="level3">
<h3 class="anchored" data-anchor-id="pablo-and-his-mom-moved-in-with-his-aunt-and-uncle-their-4-kids-2-dogs-and-a-coop-full-of-chickens-to-save-money."><strong>Pablo and his mom moved in with his aunt and uncle, their 4 kids, 2 dogs, and a coop full of chickens to save money.</strong></h3>
<p>His sisters had to stay with their grandmother back in the village.</p>
<p>After five weeks of treatment, his aunt was convinced that he was cured. “He looks fine,” she would tell his mom, “how could he still possibly be sick?” She would also insist that many doctors are greedy and give people medicine only to make money. Over time, his mother did notice that Pablo seemed to look sicker after visiting the doctor and receiving treatment. Perhaps his aunt was right, she would think to herself.</p>
</section>
<section id="by-week-12-of-treatment-pablos-mom-felt-she-was-near-a-breaking-point." class="level3">
<h3 class="anchored" data-anchor-id="by-week-12-of-treatment-pablos-mom-felt-she-was-near-a-breaking-point."><strong>By week 12 of treatment, Pablo’s mom felt she was near a breaking point.</strong></h3>
<p>She lost her job because of her long absence, and they were dependent on financial support from extended family members who had little disposable income. Living in the full house with their relatives was cramped and noisy, and the family felt like a burden. Pablo was sick most of the time and would cry at night because he missed his sisters.</p>
<p>His mom tried to talk to the doctors several times about their difficulties, but she felt she didn’t get her point across in her broken Spanish, and it appeared to her that the busy doctors did not have time to understand her problems.</p>
<p>Eventually, his mother heard about a traditional religious healer near their village whose treatments were much cheaper. She talked with several family members who told her the traditional healer had helped them when they were sick. This was enough to help her make the decision.</p>
</section>
<section id="that-day-they-packed-up-and-returned-to-their-home.-they-said-nothing-to-their-doctors-nor-did-they-return-to-finish-treatment." class="level3">
<h3 class="anchored" data-anchor-id="that-day-they-packed-up-and-returned-to-their-home.-they-said-nothing-to-their-doctors-nor-did-they-return-to-finish-treatment."><strong>That day they packed up and returned to their home. They said nothing to their doctors, nor did they return to finish treatment.</strong></h3>
<p>Cancer treatment can be a brutal journey, but if the entire treatment is not finished, the patient is at extremely high risk for the aggressive return of their disease.</p>
<p>This narrative illustrates the corrosive effects of cancer on the whole family.</p>
<ul>
<li><p>Financial difficulties</p></li>
<li><p>Geographic barriers to care</p></li>
<li><p>Disrupted life rhythms and social strain</p></li>
<li><p>Poor communication with the healthcare team</p></li>
<li><p>Poor understanding of cancer and how to successfully treat it</p></li>
<li><p>Reliance on extended family for material and financial support</p></li>
</ul>
</section>
<section id="the-answer-to-treatment-abandonment-is-to-understand-the-difficulties-of-a-familys-journey-and-support-them-through-it." class="level3">
<h3 class="anchored" data-anchor-id="the-answer-to-treatment-abandonment-is-to-understand-the-difficulties-of-a-familys-journey-and-support-them-through-it."><strong>The answer to treatment abandonment is to understand the difficulties of a family’s journey and support them through it.</strong></h3>
<p>There is nothing overly complex here. Families need support during the treatment journey. Financial assistance, material support with food and housing assistance, improved family education and communication with the healthcare team, and initiatives about how communities can support families through treatment all help to <strong>dramatically</strong> reduce treatment abandonment rates. There is a significant body of published research that demonstrates the efficacy of all of these interventions.</p>
<p>The link between family support and the successful completion of treatment is so strong, that many providers argue it should be prioritized as important as medicine or surgery.</p>
</section>
<section id="supporting-families-financially-psychologically-socially-and-spiritually-is-an-essential-part-of-pediatric-cancer-treatment." class="level3">
<h3 class="anchored" data-anchor-id="supporting-families-financially-psychologically-socially-and-spiritually-is-an-essential-part-of-pediatric-cancer-treatment."><strong>Supporting families financially, psychologically, socially, and spiritually is an essential part of pediatric cancer treatment.</strong></h3>
<p><br>
</p>


</section>

 ]]></description>
  <category>Global PHO</category>
  <guid>https://www.thedoctorsdialectic.com/docs/posts/2022-04-10-pediatric_abandonment/index.en.html</guid>
  <pubDate>Sun, 10 Apr 2022 05:00:00 GMT</pubDate>
</item>
<item>
  <title>How to measure anything in Global Health: 5. Calibration techniques</title>
  <dc:creator>Mark Zobeck</dc:creator>
  <link>https://www.thedoctorsdialectic.com/docs/posts/2022-04-07-htma-5-calibration-techniques/index.en.html</link>
  <description><![CDATA[ 




<p><a href="https://www.thedoctorsdialectic.com/2022/04/06/htma-4-calibrate-your-judgement/">In my previous essay</a>, I discussed how calibrating your judgments is a crucial step when measuring anything in global health.</p>
<p>For instance, if you want to estimate the likelihood a new cancer treatment causes severe side effects, then a calibrated estimator can offer a 90% uncertainty interval about a plausible range of side effect rates as a starting place for measurement.</p>
<p>Although it is essential in the measurement process, calibration can be a tricky state to achieve.</p>
<section id="here-are-5-recommendations-for-how-to-achieve-calibration-with-your-judgment." class="level2">
<h2 class="anchored" data-anchor-id="here-are-5-recommendations-for-how-to-achieve-calibration-with-your-judgment."><strong>Here are 5 recommendations for how to achieve calibration with your judgment.</strong></h2>
<p>This material comes from Douglas Hubbards marvelous book, <em>How to Measure Anything</em>. I recommend you read the book if these posts interest you. You will find much more thorough explanations of these concepts there.</p>
<section id="the-equivalent-bet-test" class="level3">
<h3 class="anchored" data-anchor-id="the-equivalent-bet-test"><strong>1. The equivalent bet test</strong></h3>
<p>Ask yourself, would you rather accept a bet to win <code>$1000</code> if the true value falls in your uncertainty interval or accept a bet to spin a roulette wheel with a wedge of 10% of its area where you win nothing and 90% of its area where you win <code>$1000</code>. If you are calibrated, you should be indifferent between these bets. If you prefer your uncertainty interval, you’re overconfident. If you prefer the wheel, you’re underconfident.</p>
</section>
<section id="the-premortem-test" class="level3">
<h3 class="anchored" data-anchor-id="the-premortem-test"><strong>2. The premortem test</strong></h3>
<p>Explain what would be wrong with your interval if the true value turns out to be outside your interval. If you can come up with a plausible failure mode, then perhaps your interval is too narrow.</p>
</section>
<section id="test-the-limits" class="level3">
<h3 class="anchored" data-anchor-id="test-the-limits"><strong>3. Test the limits</strong></h3>
<p>Exam the lower limit, then the upper limit of the interval. For a 90% interval, 95% of the plausible values should be above the lower limit. Does your limit reflect that estimate? Then move to the upper limit and assess it its plausible that 95% of values are below that limit. This helps to avoid anchoring bias, something I found myself susceptible to as I started exploring calibration.</p>
</section>
<section id="the-absurdity-test" class="level3">
<h3 class="anchored" data-anchor-id="the-absurdity-test"><strong>4. The absurdity test</strong></h3>
<p>Start with an absurdly wide range and progressively narrow it, explaining why it can’t be that wide along the way. This test helps to locate the edge of our knowledge about the estimate by eliminating things that are obviously not correct.</p>
</section>
<section id="repetition-and-feedback" class="level3">
<h3 class="anchored" data-anchor-id="repetition-and-feedback"><strong>5. Repetition and feedback</strong></h3>
<p>Go to the <a href="https://www.howtomeasureanything.com/3rd-edition/">HTMA website</a> and download the calibration tests to take, or make up your own questions, estimate the answers, and grade them. Calibration is not a skill that comes naturally to most people, but is a skill that must be practiced. There’s <a href="https://www.journals.uchicago.edu/doi/full/10.1093/reep/rex022#_i30">a large body of literature on the topic you can also reference</a>, something I was unfamiliar with until recently.</p>
<p>It takes a little time and effort, but soon you can calibrate your judgment to measure anything in global health that will improve the care you provide to your patients!</p>


</section>
</section>

 ]]></description>
  <category>Data Science + Global Health</category>
  <guid>https://www.thedoctorsdialectic.com/docs/posts/2022-04-07-htma-5-calibration-techniques/index.en.html</guid>
  <pubDate>Thu, 07 Apr 2022 05:00:00 GMT</pubDate>
</item>
<item>
  <title>How to measure anything in Global Health: 4. Calibrate your judgment</title>
  <dc:creator>Mark Zobeck</dc:creator>
  <link>https://www.thedoctorsdialectic.com/docs/posts/2022-04-06-htma-4-calibrate-your-judgement/index.en.html</link>
  <description><![CDATA[ 




<p><strong>Your personal calibration is one of the most important measurement skills you’ve never heard of.</strong></p>
<p>Difficult measurement problems in Global Health require experts to provide an initial estimate of uncertainty about the variables in the process that produce an outcome. For instance, suppose to want to use a new treatment, drug X, for a cancer, but we are concerned the drug will cause harm through serious side effects. As a first step to measure this concern, an expert should estimate her 90% uncertainty interval of the probability that the drug causes harm.</p>
<p>What in the world is an uncertainty interval, and how will we know if the expert’s estimates are any good?</p>
<p>Like the last few posts, this content is from the delightful book <em>How to Measure Anything</em> by Douglas Hubbard.</p>
<section id="uncertainty-intervals-are-ranges-of-estimated-variable-values" class="level3">
<h3 class="anchored" data-anchor-id="uncertainty-intervals-are-ranges-of-estimated-variable-values"><strong>Uncertainty intervals are ranges of estimated variable values</strong></h3>
<p>These ranges should capture all of the plausible values that a particular variable may have. If we say it is a <em>90%</em> uncertainty interval, then the range of values should be wide enough so that if 100 such intervals were constructed, 90 of them would contain the correct value. These intervals should capture the expert’s uncertainty about the value while still signifying the range of plausible values the variable may take.</p>
<p>For the example with drug X, our expert may use her clinical experience with the drug in other contexts to estimate the rate of rare but serious side effects is between 1 per 100 doses to 10 per 100 doses.</p>
<p>Great, we have an interval, but how do we know if it is truly a <em>90%</em> uncertainty interval?</p>
</section>
<section id="experts-judgment-should-be-calibrated" class="level3">
<h3 class="anchored" data-anchor-id="experts-judgment-should-be-calibrated"><strong>Experts’ judgment should be <em>calibrated</em></strong></h3>
<p>Calibration means that the uncertainty interval performs as expected.</p>
<p>Calibrated 70% uncertainty intervals mean that truly 7 in 10 such intervals contain the true value. If 4/10 intervals contained the true value, then the expert is overconfident. If 9/10 intervals contain the true values, then the expert might be underconfident.</p>
<p>Similarly, for true/false questions, calibration can be estimated by assigning your subjective probability that your answer choice is correct. If you answer questions that you are 60% confident in, that means you believe you would answer 6 in 10 such questions correctly. If you answer 4/10 such questions correctly, you’re overconfident, if you answer 9/10 correctly, you’re underconfidence.</p>
</section>
<section id="calibrate-yourself" class="level3">
<h3 class="anchored" data-anchor-id="calibrate-yourself"><strong>Calibrate yourself</strong></h3>
<p>How do you calibrate yourself?</p>
<p>Test your calibration. No literally, I mean answer questions and produce 90% uncertainty intervals or estimate your confidence in your true/false answers and see how you do.</p>
<p>Here are two questions from HTMA to get you started:</p>
<blockquote class="blockquote">
<p><strong>Assing a 90% uncertainty interval:</strong> How many inches long is the average business card?</p>
<p><strong>Indicate true or false and the probability you’re correct:</strong> A gallon of oil weighs less than a gallon of water.</p>
</blockquote>
<p>Random questions, but if you think through what you already know, you can come up with a range of plausible values or a probabilistic estimate of your confidence.</p>
<p>These are just example questions. <a href="https://www.howtomeasureanything.com/3rd-edition/">At HTMA’s website</a>, you can find several tests of both types of questions and their answers so that you can assess your own calibration!</p>
<p>There is <em>a lot</em> more to this story and calibration can certainly go wrong. We will discuss more in future posts, but for now, I encourage you to go take a test and assess your own calibration.</p>
<p>I’ll admit, I was woefully overconfident on my first go around.</p>
<p>But that is why we calibrate!</p>


</section>

 ]]></description>
  <category>Data Science + Global Health</category>
  <guid>https://www.thedoctorsdialectic.com/docs/posts/2022-04-06-htma-4-calibrate-your-judgement/index.en.html</guid>
  <pubDate>Wed, 06 Apr 2022 05:00:00 GMT</pubDate>
</item>
<item>
  <title>How to measure anything in Global Health: 3. The Definition of Risk</title>
  <dc:creator>Mark Zobeck</dc:creator>
  <link>https://www.thedoctorsdialectic.com/docs/posts/2022-04-05-htma-3-definition-of-risk/index.en.html</link>
  <description><![CDATA[ 




<p>What are the chances that survival from a cancer decrease after introducing a new treatment in your clinic?</p>
<section id="when-trying-to-measure-anything-in-global-health-we-need-to-understand-the-definition-of-risk." class="level3">
<h3 class="anchored" data-anchor-id="when-trying-to-measure-anything-in-global-health-we-need-to-understand-the-definition-of-risk."><strong>When trying to measure anything in global health, we need to understand the definition of risk.</strong></h3>
<p>Suppose you want to improve the outcome of Burkitt lymphoma (BL) using drug X. This drug is well researched in the literature and has been proven to increase survival in high-income countries. You also know a side effect of drug X causes patients to be at risk for severe infections. Clinics in resource-limited settings may have difficulty providing the same level of supportive care as in high-income countries, and mortality may increase due to the risk of infection.</p>
<p>Is there a way to <em>a priori</em> estimate the likelihood that drug X actually <em>decreases</em> survival due to the toxicity it causes?</p>
<p>We will work through this problem in the next few essays. Today, we need to more precisely define the risk of introducing drug X. These definitions come from Douglas Hubbard’s amazing book, <em>How to Measure Anything</em>. It is worth your time to read if this subject interests you.</p>
<p>First, we will define uncertainty, then risk.</p>
</section>
<section id="uncertainty-the-existence-of-more-than-one-possibility-and-the-true-outcomestateresultvalue-is-unknown." class="level3">
<h3 class="anchored" data-anchor-id="uncertainty-the-existence-of-more-than-one-possibility-and-the-true-outcomestateresultvalue-is-unknown."><strong>Uncertainty: The existence of more than one possibility, and the true outcome/state/result/value is unknown.</strong></h3>
<p>For our example, we are uncertain because the drug either does or does not improve survival.</p>
</section>
<section id="risk-a-state-of-uncertainty-where-some-of-the-possibilities-involve-a-loss-catastrophe-or-other-undesirable-outcome." class="level3">
<h3 class="anchored" data-anchor-id="risk-a-state-of-uncertainty-where-some-of-the-possibilities-involve-a-loss-catastrophe-or-other-undesirable-outcome."><strong>Risk: A state of uncertainty where some of the possibilities involve a loss, catastrophe, or other undesirable outcome.</strong></h3>
<p>The important part of this definition is that it requires a way to attach <em>values</em> to outcomes. Outcomes with positive values are commonly called benefits, and with negative values, risks.</p>
<p>To make decisions in the face of uncertainty and risk, we attach probabilities to the possibilities of our uncertain value so that we have a <em>measure of uncertainty.</em> The total probability of the outcomes with negative values are the <em>measure of risk.</em></p>
<p>For example, we might think there is anywhere between 1%-50% chance that patients experience severe toxicities from drug X. This is highly uncertain.</p>
<p>Measurements will improve our decision by reducing our uncertainty about the probability of risk or harm from drug X. For example, conducting a small pilot study of 40 patients demonstrates the incidence of severe toxicities is around 5%.</p>
<p>It is nearly certain that 5% will not be the incidence of severe toxicities in all the patients, but this is a very useful measurement that can help you narrow your assessment of the true chance of severe toxicity to be between, say 2%-10%. This much narrower range will aid you in making an evidence-based decision about whether the risks outweigh the benefits.</p>
<p>There is much more to the process, but this is a good demonstration of the fundamental purpose of measuring uncertainty and risk:</p>
</section>
<section id="good-measurements-make-you-less-wrong-about-important-questions." class="level3">
<h3 class="anchored" data-anchor-id="good-measurements-make-you-less-wrong-about-important-questions."><strong>Good measurements make you less wrong about important questions.</strong></h3>


</section>

 ]]></description>
  <category>Data Science + Global Health</category>
  <guid>https://www.thedoctorsdialectic.com/docs/posts/2022-04-05-htma-3-definition-of-risk/index.en.html</guid>
  <pubDate>Tue, 05 Apr 2022 05:00:00 GMT</pubDate>
</item>
<item>
  <title>How to measure anything in Global Health: 2. The universal approach to measurement</title>
  <dc:creator>Mark Zobeck</dc:creator>
  <link>https://www.thedoctorsdialectic.com/docs/posts/2022-04-04-htma-2-universal_approach/index.en.html</link>
  <description><![CDATA[ 




<p>If you want to use data to improve treatment delivery in global health, all of your measurements should support decisions.</p>
<p>For example, suppose you run an oncology clinic and consider introducing a new treatment, drug X, into your current treatment regimen for Burkitt lymphoma (BL). It has been proven in studies in the United States to improve outcomes by 10% in BL. It is also expensive, has side effects that may increase toxicity, and will take additional clinic capacity and new workflows to administer. Should you start to offer drug X for BL?</p>
<p><strong>To decide, use the <em>universal approach to measurement</em> to reduce uncertainty about the possible outcomes.</strong></p>
<p>This material comes from <em>How to Measure Anything</em> (HTMA), the legendary book by Douglas Hubbard that, you guessed it, teaches you to measure anything. Check out the book if you like this material.</p>
<section id="define-a-decision-problem-and-the-relevant-uncertainties" class="level2">
<h2 class="anchored" data-anchor-id="define-a-decision-problem-and-the-relevant-uncertainties"><strong>1. Define a decision problem and the relevant uncertainties</strong></h2>
<p>Precisely specify the decision you are trying to make - “Should we add drug X to the treatment for intermediate and high-risk BL or continue with current therapy?” Also, specify the unknowns that will impact the decision - “We need to know the improvement in survival, cost, possible toxicities and required supportive therapies, and requirements and cost associated with administration of the drug.” Relate how the values of the variables combine to produce the decision. Be very specific.</p>
</section>
<section id="determine-what-you-know-now" class="level2">
<h2 class="anchored" data-anchor-id="determine-what-you-know-now"><strong>2. Determine what you know now</strong></h2>
<p>Use the content experts to describe and quantify the current level of uncertainty. HTMA recommends calibrating the content experts through a series of exercises to have them estimate their 90% uncertainty intervals for a variety of estimation tasks. We’ll cover this more in upcoming essays.</p>
</section>
<section id="compute-the-value-of-additional-information" class="level2">
<h2 class="anchored" data-anchor-id="compute-the-value-of-additional-information"><strong>3. Compute the value of additional information</strong></h2>
<p>“Information has value because it reduces risk in decisions.” Identify high-value variables to measure by estimating how much value you will gain by being more certain about the variables listed in step 1. How would it affect your decision if your uncertainty about the total cost of the drug went from $500-$5,000 per patient to $800-$1500 per patient? HTMA has much to say on this, which we will cover in the future.</p>
</section>
<section id="apply-the-relevant-measurement-instruments-to-high-value-measurements" class="level2">
<h2 class="anchored" data-anchor-id="apply-the-relevant-measurement-instruments-to-high-value-measurements"><strong>4. Apply the relevant measurement instruments to high-value measurements</strong></h2>
<p>Apply simple measurement methods to reduce your uncertainty about the high-value variables identified in steps 1-4. There are many excellent, low-cost ways to accomplish this task, which I will address in time.</p>
</section>
<section id="make-a-decision-and-act-on-it" class="level2">
<h2 class="anchored" data-anchor-id="make-a-decision-and-act-on-it"><strong>5. Make a decision and act on it</strong></h2>
<p>After measurement, integrate what you know into the decision pathways in step 1 and estimate the balance of risk versus reward for the different decisions.</p>
<p>Then decide and have confidence in your glorious theory-informed, evidence-based, measurement-backed decision to improve your patients’ care.</p>


</section>

 ]]></description>
  <category>Data Science + Global Health</category>
  <guid>https://www.thedoctorsdialectic.com/docs/posts/2022-04-04-htma-2-universal_approach/index.en.html</guid>
  <pubDate>Mon, 04 Apr 2022 05:00:00 GMT</pubDate>
</item>
<item>
  <title>How to measure anything in Global Health: 1. Foundations of Measurement</title>
  <dc:creator>Mark Zobeck</dc:creator>
  <link>https://www.thedoctorsdialectic.com/docs/posts/2022-04-03-htma-1-foundations/index.en.html</link>
  <description><![CDATA[ 




<p>Can you measure the effect of adding a dietitian to your clinical service?</p>
<p>Can you quantify how lonely your patients feel while undergoing treatment?</p>
<p>Can you estimate the years of life saved from a quality improvement project?</p>
<p><strong>The answer to all of these things is yes, it is possible to measure anything in Global Health</strong>, although the answers may not be what you expect.</p>
<p>This is good news because measurement can help leaders make decisions that efficiently improve the care they provide to patients.</p>
<p>In this series of posts, I’m going to work through the techniques to measure anything in global health. These ideas come from the phenomenal book <em>How to Measure Anything</em> (HTMA)by Douglas Hubbard. Buy the book if you are interested in this topic. It’s awesome.</p>
<p><strong>To measure anything in Global Health, we need to understand:</strong></p>
<ul>
<li><p>The concept of measurement</p></li>
<li><p>The objective of measurement</p></li>
<li><p>The methods of measurement</p></li>
</ul>
<p>If you can understand these three foundations, you are well on your way to measuring anything in global health.</p>
<section id="the-concept-of-measurement" class="level3">
<h3 class="anchored" data-anchor-id="the-concept-of-measurement"><strong>The Concept of Measurement:</strong></h3>
<blockquote class="blockquote">
<h3 id="a-quantitatively-expressed-reduction-of-uncertainty-based-on-one-or-more-observations." class="anchored"><strong>“A quantitatively expressed reduction of uncertainty based on one or more observations.”</strong></h3>
</blockquote>
<p>Measurement is not about being right; it is about being less wrong. With the view of making decisions to improve future outcomes, any reduction in the uncertainty of how the future may look will improve the value of your decision.</p>
<p>How many mechanical ventilators will the critical care unit require in the next COVID wave? If before measurement you think its somewhere between 5 and 50 and after the measurement you narrow it to 20-30, that will give you a much better chance at providing all patients the resources they need without breaking the bank.</p>
</section>
<section id="the-objective-of-measurement" class="level3">
<h3 class="anchored" data-anchor-id="the-objective-of-measurement"><strong>The Objective of Measurement</strong></h3>
<p>Many things seem impossible to measure because they seem “intangible”. For instance, think about how to measure loneliness in patients. That seems like a hard thing to measure. HTMA gives some helpful advice to clarify how to measure the intangible:</p>
<blockquote class="blockquote">
<ol type="1">
<li><p>If it matters at all, it is detectable/observable</p></li>
<li><p>If it is detectable, it can be detected as an amount or range of possible amounts</p></li>
<li><p>If it can be detected as a range of possible amounts, it can be measured</p></li>
</ol>
</blockquote>
<p>Loneliness is an emotion that can be expressed through words and actions. We can develop methods to capture these expressions of loneliness to understand the patient’s internal state.</p>
<p>Another key point is that you don’t have to reinvent the wheel - there is a lot of literature about the psychometrics of loneliness where researchers have grappled with 1-3 above.</p>
</section>
<section id="the-methods-of-measurement" class="level3">
<h3 class="anchored" data-anchor-id="the-methods-of-measurement"><strong>The Methods of Measurement</strong></h3>
<p>Even if you understand the concept and objective of measurement, the act of measurement may still seem daunting. Many simple methods, such as random sampling, produce useful measurements with few resources. More complex methods can increase the quality of measurement at the cost of more effort. How complex you want to be will be determined by the importance of measurement for your decision.</p>
<p>HTMA will go through methods that allow you to reliably measure…</p>
<blockquote class="blockquote">
<ul>
<li><p>..with a very small random sample of a very large population</p></li>
<li><p>…when many other, even unknown, variables are involved</p></li>
<li><p>…the size of a mostly unseen population</p></li>
<li><p>…subjective preferences and values</p></li>
<li><p>…the risk of rare events</p></li>
</ul>
</blockquote>
<p>One simple method example: we can show there is a 93.75% chance that the median value of a population will fall between the smallest and largest values of a random sample of five observations.</p>
<p>That is incredibly useful when your uncertainty about the range of possible median values is high.</p>
<p>These three foundational concepts will set you up for success the next time you try to measure anything!</p>


</section>

 ]]></description>
  <category>Data Science + Global Health</category>
  <guid>https://www.thedoctorsdialectic.com/docs/posts/2022-04-03-htma-1-foundations/index.en.html</guid>
  <pubDate>Sun, 03 Apr 2022 05:00:00 GMT</pubDate>
</item>
<item>
  <title>Distributed intelligence is the key to success for high-performing health systems in Global Health</title>
  <dc:creator>Mark Zobeck</dc:creator>
  <link>https://www.thedoctorsdialectic.com/docs/posts/2022-04-02-distributed_intelligence/index.en.html</link>
  <description><![CDATA[ 




<p>Who would you rather have care for you: the world’s smartest doctor in a poorly-function health system or a mediocre doctor in a high-functioning health system?</p>
<p><strong>Take the high-functioning health system every time.</strong></p>
<p>Genius doctors are still humans who can move and think only at the speed of a single person.</p>
<p>Even if the doctor has limitless energy, she can only see so many patients in one day, make so many diagnoses, and fill so many prescriptions. Be ready for the long wait to see her.</p>
<p>Of course, even the best doctor makes mistakes, but without a system to back her up, there is no safety net when she fails without a system to back her up.</p>
<p>Every doctor occasionally needs management advice from colleagues, but being the best of the bunch there will be nowhere to whom she can turn.</p>
<p>She needs backup. She needs a system.</p>
<section id="what-is-distributed-intelligence" class="level2">
<h2 class="anchored" data-anchor-id="what-is-distributed-intelligence"><strong>What is distributed intelligence?</strong></h2>
<p>The <a href="https://www.isls.org/research-topics/distributed-intelligence/">International Society of Learning Sciences</a> gives a helpful outline of the concept:</p>
<ul>
<li><p>Distributed intelligence means that the resources that enable and mediate activity are distributed in configuration across people, environments, situations, and time.</p></li>
<li><p>Intelligence is assembled and accomplished rather than possessed.</p></li>
<li><p>Therefore, the boundary unit of analysis for learning is different with this orientation since intelligence “comes to life” in human activity.</p></li>
</ul>
<p>This view acknowledges that no one person is smart enough to know everything that needs to be known or can move fast enough to do everything that needs to be done. Instead, each person acts together with others to accomplish the system’s goal.</p>
<p>Intelligence is found in the motion of the whole system and not its constituent parts. In such systems, information is often distributed in the form of workflows, best practices, reference documents, technologies, teams, and cultures.</p>
</section>
<section id="distributed-intelligence-in-healthcare." class="level2">
<h2 class="anchored" data-anchor-id="distributed-intelligence-in-healthcare."><strong>Distributed intelligence in healthcare.</strong></h2>
<p>The totality of clinical knowledge in existence far exceeds the expertise of any single physician. When a doctor encounters a diagnosis he is unfamiliar with, he must call for help from a specialist.</p>
<p>Even for specialists, there are times when a diagnosis requires a rarely used therapy, and she must consult institutional guidelines on how to order and administer a specific medicine.</p>
<p>If a patient is taking other medications, guidelines may not be sufficient to dose the medicine properly, and a pharmacist must be consulted who references an online interaction database.</p>
<p>The patient must be scheduled in an infusion room to receive the medication. The presence of the patient, the medicine, a nurse who can give it, and equipment for the infusion must be coordinated by the facilities staff.</p>
<p>While the patient receives the medication, the nurse must monitor his vital signs and alerts a physician if any measurement exceeds the boundaries derived from research and past clinical experience encoded into clinical guidelines.</p>
<p>Where is the intelligence here? It is in the entire description. The patient was diagnosed and received the needed therapy because of the interacting actions between the doctor, specialist, guidelines, pharmacist, database, scheduling system, nurse, and clinical guidelines.</p>
<p>The system knew how to diagnose and treat the patient even though no single person did.</p>
</section>
<section id="data-science-distributes-intelligence-in-a-health-system." class="level2">
<h2 class="anchored" data-anchor-id="data-science-distributes-intelligence-in-a-health-system."><strong>Data science distributes intelligence in a health system.</strong></h2>
<p><a href="https://www.thedoctorsdialectic.com/2022/03/21/let-the-data-flow/">As I have written previously</a>, data science is essential in global health because it allows information to flow where it is needed in the system, unlocking its intelligence and allowing patients to receive the care they require.</p>


</section>

 ]]></description>
  <category>Data Science + Global Health</category>
  <guid>https://www.thedoctorsdialectic.com/docs/posts/2022-04-02-distributed_intelligence/index.en.html</guid>
  <pubDate>Sat, 02 Apr 2022 05:00:00 GMT</pubDate>
</item>
<item>
  <title>Stochastic beasts and how to slay them - Part 1</title>
  <dc:creator>Mark Zobeck</dc:creator>
  <link>https://www.thedoctorsdialectic.com/docs/posts/2022-03-25-stochastic-beasts-1/index.en.html</link>
  <description><![CDATA[ 




<p>What do the Balrogs, huge earthquakes, and nuclear war have in common?</p>
<p>They are all unpredictable demons that emerge from the abyss to destroy your future. While Balrogs may be mythical beasts from Middle Earth, earthquakes and nuclear war are very real threats.</p>
<p><a href="https://www.thedoctorsdialectic.com/2022/03/24/two_types_of_uncertainty/">In my last post,</a> I discussed the two types of uncertainty, aleatory and epistemic. I described them with nice and tidy examples, consistent with how they are usually presented in classroom settings. These tame illustrations were a good start to illustrate the concepts so that you can recognize them when you come across them.</p>
<p>Unfortunately, real life is not tame. There are radical forms of both aleatory and epistemic uncertainty. These are events that are completely unpredictable, although in slightly different ways.</p>
<p>It is good to understand these forms of uncertainty so that you can face them confidently when they come.</p>
<p>In this post, we will discuss slaying aleatory beasts and in the next post cover epistemic monsters.</p>
<section id="radical-aleatory-uncertainty" class="level2">
<h2 class="anchored" data-anchor-id="radical-aleatory-uncertainty">Radical aleatory uncertainty</h2>
<p>The frequency of earthquakes follows an inverse power law as a function of its strength. In other words, stronger earthquakes happen much less frequently than weaker earthquakes. This means you can live in faulty California your whole life and never experience a strong earthquake, although you will probably experience many small and medium-size earthquakes in that time.</p>
<p>This is radical aleatory uncertainty: big events that happen infrequently but conform to mathematical laws. There are underlying physical reasons why earthquakes conform to an inverse power law, which means we can make scientific models that describe their occurrence. Their infrequency also makes them unpredictable, and therein lies the problem.</p>
<p>Radical aleatory uncertainty can lull you to sleep. It’s easy to think that because you’ve done fine in small earthquakes, you’ll be fine in a big one, but those are two completely different beasts. It’s tempting to save money by building less resilient housing when an earthquake hasn’t knocked anything down in a while.</p>
<p>Also, you can take a false sense of security from the fact that we can model the earthquake scientifically, therefore we must have some special insight into how to predict them. Describing their frequency and predicting the next occurrence are two wildly different activities, and we cannot do the latter.</p>
</section>
<section id="slaying-aleatory-beasts" class="level2">
<h2 class="anchored" data-anchor-id="slaying-aleatory-beasts">Slaying aleatory beasts</h2>
<p>There is nothing we can do about earthquakes. We aren’t going to geoengineer them away. This applies to many things that exhibit radical aleatory uncertainty. So what to do?</p>
<p>Stay awake. The threats are real and describable mathematically, so take reasonable precautions against them. Take out insurance to protect against rare but serious catastrophes. Keep emergency supplies stocked if you live in an area exposed to natural disasters. Hedge risky in investments with safer bets. Do not over-optimize to your present situation but spend a little extra effort to build in robustness. Advocate for policies and vote for politicians that take small-but-consequential risks seriously and who won’t give in to political expediency.</p>
<p>Also, don’t let these uncertainties dominate your life. Stay alert to their possibility, but take seriously the fact that they are rare. If you’re thinking about the structural integrity of the restaurant you’re at with your date, then the beast is winning. Aleatory anxiety is a very real threat to your well-being. To ward it off, I find it helpful to understand the beast in its rare-but-serious mathematical context.</p>
<p>These stochastic beasts are hard to slay, there is no doubt about it. The experience of radical uncertainty is a fundamental part of what makes us human. It may not always be fun to face them, but it is possible to live confidently in the knowledge that you can handle the aleatory beasts come your way.</p>


</section>

 ]]></description>
  <category>Confident Uncertainty</category>
  <guid>https://www.thedoctorsdialectic.com/docs/posts/2022-03-25-stochastic-beasts-1/index.en.html</guid>
  <pubDate>Fri, 25 Mar 2022 05:00:00 GMT</pubDate>
</item>
<item>
  <title>Understanding the two types of uncertainty will help you live more confidently in a stochastic world</title>
  <dc:creator>Mark Zobeck</dc:creator>
  <link>https://www.thedoctorsdialectic.com/docs/posts/2022-03-24-two-types-of-uncertainty/index.en.html</link>
  <description><![CDATA[ 




<p>We live in a complex and often chaotic world. To live confidently, we have to know how to navigate uncertain paths.</p>
<p>We make decisions every single day. What do you eat in the morning? What route should you take to work? Do you invest in a certain stock? Do you hire a new employee? Etc…</p>
<p>How do we make good decisions when the outcomes are uncertain? We have to first understand the two types of uncertainty that are present in any decision because each type requires its own response.</p>
<section id="aleatory-uncertainty" class="level2">
<h2 class="anchored" data-anchor-id="aleatory-uncertainty">Aleatory uncertainty</h2>
<p>Aleatory uncertainty is uncertainty due to the inherent randomness in a process. Think of a single flip of a fair coin. There is a 50% chance it comes up heads and a 50% chance it comes up tales. Or think of the thoroughly shaken-up role of a fair die. There is a one in six chance of getting a 1 on every role. These probabilities are inherent in the system generating the outcome (coin flips and dice rolls) and there is no way to reduce the uncertainty about it.</p>
</section>
<section id="epistemic-uncertainty" class="level2">
<h2 class="anchored" data-anchor-id="epistemic-uncertainty">Epistemic uncertainty</h2>
<p>Epistemic uncertainty is your uncertainty about the outcome of a decision. This uncertainty is reducible by gaining knowledge. It is uncertainty that exists in the mind of the observer and could be reduced through empirical evidence or logical argument. What is the atomic number of zenon? How long is your left 3rd toe? Who was the first cartoonist to draw Donal Duck? These are all things one is likely uncertain about right now but could Google or measure if needed.</p>
</section>
<section id="bringing-the-two-types-together" class="level2">
<h2 class="anchored" data-anchor-id="bringing-the-two-types-together">Bringing the two types together</h2>
<p>Suppose you have a bag of 20 marbles, and I ask you to predict the color of the next marble you pull out. You know some are blue and some red, but you don’t know the relative proportions of each in the bag. There is both aleatory and epistemic uncertainty present in this scenario. If you were to start drawing marbles and put them to the side, you could count the relative proportions of what you draw out as you go and your epistemic uncertainty about that slowly reduce with each draw. Suppose you see 80% of the marbles are red and then dump them back in the bag. Now you know there is an 80% chance you will pull out a red marble on the next draw, which is the aleatory uncertainty inherent in the system. You’ve reduced your epistemic uncertainty as far as it can go, and now the rest is left up to aleatory chance.</p>
</section>
<section id="living-in-light-of-uncertainty" class="level2">
<h2 class="anchored" data-anchor-id="living-in-light-of-uncertainty">Living in light of uncertainty</h2>
<p>Differentiating the two types of uncertainty is important because each has its own approach. When faced with high epistemic uncertainty, the answer is to get more information. Reduce the epistemic uncertainty in decisions as far as you are able within your means and time constraints. If you hit mostly aleatory uncertainty, then there is nothing you can do to reduce it further unless you break the whole system, which is rarely an option but something to consider. If you can’t intervene in the system, then you have to decide what benefits do you get from each potential outcome. If the benefits of a lower probability outcome far outway the benefits of a higher probability outcome, then it might make sense to go for the former. You’ve reached the point where you have to know what you want and decide if the probability of the outcome described by the aleatory uncertainty gives you enough payoff so that you should go for it.</p>
<p>Understanding these two types of uncertainty will help you take steady steps along uneven ground and navigate successfully to your utility-maximized future.</p>
<p>…Of course, nothing is ever that neat and tidy. Especially in this uncertain world. This is a good start but someday we’ll have to talk about monsters that emerge from the dark abyss of radical uncertainty.</p>


</section>

 ]]></description>
  <category>Confident Uncertainty</category>
  <guid>https://www.thedoctorsdialectic.com/docs/posts/2022-03-24-two-types-of-uncertainty/index.en.html</guid>
  <pubDate>Thu, 24 Mar 2022 05:00:00 GMT</pubDate>
</item>
<item>
  <title>Data science is a saddle for the epistemic rodeo: healthcare as a complex system</title>
  <dc:creator>Mark Zobeck</dc:creator>
  <link>https://www.thedoctorsdialectic.com/docs/posts/2022-03-22-data-science-and-the-epistemic-rodeo/index.en.html</link>
  <description><![CDATA[ 




<p>Healthcare is complicated. Healthcare is also complex. To use data science to improve treatment delivery in low-resource settings, it is important to understand in what way healthcare is complicated and in what was it is complex.</p>
<p>We will turn to the <a href="https://hbr.org/2007/11/a-leaders-framework-for-decision-making">Cynefin</a> (pronounced ku-nev-in) framework to understand the difference between complicated and complex contexts.</p>
<ul>
<li><p>Complicated - the domain of experts, clear cause-and-effect relationships but it requires knowledge and expertise to arrive reliably at the right answers</p></li>
<li><p>Complex - dynamic system, changing, non-stationary cause-effect relationships, right answer may not exist but best answers for a unique situtions may be found by interacting carefully with the system</p></li>
</ul>
<section id="clinical-care-is-complicated" class="level2">
<h2 class="anchored" data-anchor-id="clinical-care-is-complicated"><strong>Clinical care is complicated</strong></h2>
<p>Doctors and nurses require incredible expertise to do their job well. We know a lot about the human body and about a multitude of disease states. Providers use that knowledge to gather data about the patient’s clinical presentation to arrive at a correct diagnosis or to identify effective treatments. Expert knowledge and experience is the key.</p>
<p>Importantly, although each individual patient’s body is unique and ever changing, the application of biological knowledge in the in the context of diagnosis and treatment is a stable process. Diseases act in more-or-less in predictable ways. When diseases are unpredictable, the steady application of clinical knowledge can provide further answers and treatments.</p>
</section>
<section id="healthcare-systems-are-complex" class="level2">
<h2 class="anchored" data-anchor-id="healthcare-systems-are-complex"><strong>Healthcare systems are complex</strong></h2>
<p>The healthcare system that is built to deliver care to patients is comprised of many moving parts that are hierarchically nested within functional units that interact in nonlinear ways. Hospitals, clinics, government agencies, nongovernment organizations are all key types of entities that comprise the system. Within each entity there are doctors, nurses, politicians, administrators, and many other types of actors. These entities and actors must perform many functions to deliver medical goods and services to patients. Some actors can react to the activity of others, such as changes in insurance coverage or new legislation, causing unpredictable perturbations throughout the system.</p>
<p>From the perspective of an individual clinic or hospital, these outside forces influence the treatment centers ability to care for patients in many ways. Medications must be secured, equipment must be serviced, staffing must be adequately maintained, and information systems must be kept up to date. The center’s ability to maintain these services depends on both the proper functioning of internal operations and the continued management of the ever changing external forces. Add on top of all of that the occasional pandemic or other chaotic force that emerges from the darkness to completely disrupt operations, and it can feel is if you are in an epistemic rodeo, holding on for dear life as new information tosses you about.</p>
</section>
<section id="data-science-helps-you-navigate-complex-systems" class="level2">
<h2 class="anchored" data-anchor-id="data-science-helps-you-navigate-complex-systems"><strong>Data science helps you navigate complex systems</strong></h2>
<p>Taking another insight from the Cynefin framework, in complex contexts the best way to act is to probe, sense, and respond. Probing implies that you have sensors in the system that provide information on how it evolves over time. This equips you with the ability to experiment with small changes to see how the system responds. Sensing is the act of gathering the information about the change in the system to the small changes. This should give sufficient information to know how to respond more effectively to guide the system to the desired outcome. The probe-sense-respond process is similar to several PDSA cycles in QI, but rapid sensing and flexibility with responses are key.</p>
<p>Data science provides all of the required equipment to succeed in the epistemic rodeo by allowing you to probe-sense-respond across all of your organizational complexities. Like a saddle on a bull, data science will stabilize your knowledge and give you something to hold on to as you start to feel the kick from the next challenge. Soon you’ll understand how your complex systems behaves and be able to direct it to gallop wherever you need it to go.</p>


</section>

 ]]></description>
  <category>Data Science + Global Health</category>
  <guid>https://www.thedoctorsdialectic.com/docs/posts/2022-03-22-data-science-and-the-epistemic-rodeo/index.en.html</guid>
  <pubDate>Tue, 22 Mar 2022 05:00:00 GMT</pubDate>
</item>
<item>
  <title>Let the data flow: how to move information to the people who need it in a Global Health organization</title>
  <dc:creator>Mark Zobeck</dc:creator>
  <link>https://www.thedoctorsdialectic.com/docs/posts/2022-03-21-let-the-data-flow/index.en.html</link>
  <description><![CDATA[ 




<p>If a health facility is adequately staffed with doctors, nurses, and other providers, and it is well supplied with medicines and medical equipment, then it has everything it needs to deliver care effectively, right?</p>
<p>Unfortunately, this is wrong. If effective healthcare delivery only required sufficient numbers of providers who possess sufficient equipment, then the prescription to include care in resource-constrained settings would be clear: more people and more stuff!</p>
<p>Examples abound where care is delivered ineffectively despite sufficient people with the right stuff. Patients may not be referred to the correct treatment facility. Doctors may not be able to diagnose patients effectively despite the presence of adequate laboratory and radiographic equipment. Hospital floor staff may not know which patients are sickest and need acute treatment despite vital signs being regularly obtained by nurses. While people are stuff are necessary for effective healthcare delivery, they are not sufficient. There is a missing ingredient that ties all of these examples of dysfunction together.</p>
<section id="information-flow-is-key-to-effective-healthcare-delivery" class="level2">
<h2 class="anchored" data-anchor-id="information-flow-is-key-to-effective-healthcare-delivery"><strong>Information flow is key to effective healthcare delivery</strong></h2>
<p>Information flow means that the right information comes to the right person at the right time so that effective healthcare decisions can be made.</p>
<p>Information flow during the referral process means that the clinical information about flows from the patient to the doctor, who in turn delivers the needed referral information to the patient and to the referring center, which can also reach out with visit information to the patient to assure timely arrival.</p>
<p>To obtain diagnostic information, doctors need to send patients to the lab where information can flow from the patient to a machine that transforms the results into diagnostic information that is passed back to the doctor.</p>
<p>To intervene on an acutely decompensating patient, information about the patient’s health state needs to flow to the nurses who transmit the information to physicians in a timely manner for acute intervention.</p>
</section>
<section id="information-flow-is-like-the-nervous-system-of-the-health-organization" class="level2">
<h2 class="anchored" data-anchor-id="information-flow-is-like-the-nervous-system-of-the-health-organization"><strong>Information flow is like the nervous system of the health organization</strong></h2>
<p>Information flow transmits both sensory and motor information throughout the functional units of the healthcare organism. A body can have the healthiest heart possible, but if its actions and outputs cease to be coordinated with the activity of the rest of the organs, then the organism soon falls into a very poor state of health. So too, a health system with well-trained doctors but uncoordinated actions with other providers or with laboratory equipment quickly becomes dysfunctional.</p>
</section>
<section id="information-flow-reframes-healthcare-as-a-dynamic-complex-system" class="level2">
<h2 class="anchored" data-anchor-id="information-flow-reframes-healthcare-as-a-dynamic-complex-system"><strong>Information flow reframes healthcare as a dynamic, complex system</strong></h2>
<p>Information flows show that healthcare is a dynamic system as the state of each part is constantly changing and reacting to other parts in the system. It also shows that healthcare is a complex system with many interlocking parts causing unexpected outcomes.</p>
<p>Information flow shows the connections between the parts of the system. You still may not be able to predict the long-term outcomes of a complex system, but if you can see the information flow, you can see how the system grows and changes over time so that you can slowly shape its evolutionary trajectory.</p>
</section>
<section id="people-and-stuff-are-insufficient-to-deliver-effective-care-if-information-is-not-flowing-freely-in-the-system." class="level2">
<h2 class="anchored" data-anchor-id="people-and-stuff-are-insufficient-to-deliver-effective-care-if-information-is-not-flowing-freely-in-the-system."><strong>People and stuff are insufficient to deliver effective care if information is not flowing freely in the system.</strong></h2>
<p>The goal for health systems to deliver effective care over time for all patients cannot be achieved if information does not flow in the system to coordinate and inform its activities.</p>
<p>This is why data science is a vital capability for health systems in low-resource settings. Data science can move information and provide insights as fast as the date are able to be gathered and collected. With commitment and steady effort, it is possible to build the informational nervous system that the healthcare organism needs to survive and thrive.</p>


</section>

 ]]></description>
  <category>Data Science + Global Health</category>
  <guid>https://www.thedoctorsdialectic.com/docs/posts/2022-03-21-let-the-data-flow/index.en.html</guid>
  <pubDate>Mon, 21 Mar 2022 05:00:00 GMT</pubDate>
</item>
<item>
  <title>Three essential quality control practices to improve the reliability of Data Science in Global Health</title>
  <dc:creator>Mark Zobeck</dc:creator>
  <link>https://www.thedoctorsdialectic.com/docs/posts/2022-03-20-quality-control-gh/index.en.html</link>
  <description><![CDATA[ 




<p>Quality control (QC) of data is a grind, particularly for healthcare facilities with paper charts requiring manual collection. QC takes dedicated effort sustained over the life of the project, which may extend indefinitely for data that inform the operations of a health facility.</p>
<p>QC practices assure the accuracy of the data and are absolutely essential to produce useful analyses from your data science efforts. After all, <a href="https://www.thedoctorsdialectic.com/2022/03/17/garbage-in-data-science/">data science has a garbage problem</a>, and besides <a href="https://www.thedoctorsdialectic.com/2022/03/18/unsexy-data-management/">designing a data management system to collect beautiful data</a>, QC is the best way to keep your data useful and trustworthy.</p>
<p>Here are three essential practices that every organizations that uses data to improve care should adopt.</p>
<section id="practice-1-enforced-data-conventions-and-automated-logic-checks" class="level2">
<h2 class="anchored" data-anchor-id="practice-1-enforced-data-conventions-and-automated-logic-checks"><strong>Practice 1: Enforced data conventions and automated logic checks</strong></h2>
<p>Put your software to work. Control the variable types and formats as much as possible. Enforce a common date format for all date variables, have discrete answer choices as often as possible, do your best to avoid free text fields. For numeric data, enforce low and high ranges to avoid mistypes (e.g.&nbsp;age should be between 0.0001 - 100 years). Use the internal logic of the variables to have sanity checks, such as checking that people are not listed as dead before they are born. Your data storage software should be able to handle this, and if it can’t then you need to get new software!</p>
</section>
<section id="practice-2-conduct-frequent-multidisciplinary-qc-reviews" class="level2">
<h2 class="anchored" data-anchor-id="practice-2-conduct-frequent-multidisciplinary-qc-reviews"><strong>Practice 2: Conduct frequent multidisciplinary QC reviews</strong></h2>
<p>The reviews should include at the very least a person who collected the data, a clinical person (for clinical data; pharmacist for pharmacy data, etc.), and an analyst who will be using the data to answer key questions. Reviewing the data for all new patients (or other observational units) is ideal. If there are too many data points, then reviewing key variables (e.g.&nbsp;diagnoses) and visually checking for inconsistencies (e.g.&nbsp;treatments are appropriate for the recorded diagnoses) should be the goal of the reviews. Errors and systematic inconsistencies should be addressed with the folks collecting the data. The frequency of the review depends on the volume, but every other week to monthly is a good starting place.</p>
</section>
<section id="practice-3-periodic-source-material-biopsies" class="level2">
<h2 class="anchored" data-anchor-id="practice-3-periodic-source-material-biopsies"><strong>Practice 3: Periodic source material biopsies</strong></h2>
<p>Data conventions, logic checks, and QC reviews are very good at catching error patterns, but they do not assess the accuracy of the data extracted from the source material. To do that, you will need to conduct periodic reviews of the charts. Sample a percentage of the charts, perhaps 10%, and have someone other than the person who collected the data review them for accuracy. If there are systematic errors, it will be worth expanding the biopsied number to assess the extent of the errors and the conditions under which they occur. This can be labor-intensive, so consider doing this quarterly or every 6 months.</p>
<p>With these three practices, you can overcome the QC grind and build a data pipeline that produces high-quality data that your organization can use to improve the lives of the patients you serve.</p>


</section>

 ]]></description>
  <category>Data Science + Global Health</category>
  <guid>https://www.thedoctorsdialectic.com/docs/posts/2022-03-20-quality-control-gh/index.en.html</guid>
  <pubDate>Sun, 20 Mar 2022 05:00:00 GMT</pubDate>
</item>
<item>
  <title>Aristotle’s sage advice to improve Data Science in Global Health</title>
  <dc:creator>Mark Zobeck</dc:creator>
  <link>https://www.thedoctorsdialectic.com/docs/posts/2022-03-19-aristotle-and-data-science/index.en.html</link>
  <description><![CDATA[ 




<p><strong>Aristotle</strong>, the legendary Greek philosopher, has some advice for anyone trying to use data science in global health.</p>
<blockquote class="blockquote">
<p><strong>It is the mark of an educated mind to rest satisfied with the degree of precision which the nature of the subject admits and not to seek exactness where only an approximation is possible.</strong></p>
</blockquote>
<p>Here are 3 reasons why this quote is so insightful.</p>
<section id="reason-1.-the-nature-of-your-subject-determines-how-precisely-you-can-analyze-it" class="level2">
<h2 class="anchored" data-anchor-id="reason-1.-the-nature-of-your-subject-determines-how-precisely-you-can-analyze-it"><strong>Reason 1. The nature of your subject determines how precisely you can analyze it</strong></h2>
<p>Healthcare delivery in general, and in global health in particular, is hard to measure precisely. If you’ve ever tried to conduct a quality improvement project, you know what I mean. The project starts off trying to improve a health outcome (e.g.&nbsp;“improve asthma control”), but health states are never easily captured and instead a process measure is used (“improved inhaler adherence to improve asthma control”). The further away what you want to measure is from what you can measure, the more imprecise you will be. By itself, this imprecision doesn’t prevent good analyses, but good analyses can only be done if you understand this problem.</p>
</section>
<section id="reason-2.-design-analysis-to-accommodate-imprecision" class="level2">
<h2 class="anchored" data-anchor-id="reason-2.-design-analysis-to-accommodate-imprecision"><strong>Reason 2. Design analysis to accommodate imprecision</strong></h2>
<p>Imprecision is the rule and not the exception, but there are things you can do to combat it. Measure variables as continuously as possible because more information is contained in continuous variables (continuous &gt; ordinal &gt; binary). Make sure you have enough observations to have any hope of answering the question. Learn about “directed acyclic graphs” and use them to identify which variables you need to reduce confounding and increase the precision of your analysis. These will help to maximize both the accuracy and precision of your analysis.</p>
</section>
<section id="reason-3.-dont-overfit-your-insights-to-the-imprecise-data" class="level2">
<h2 class="anchored" data-anchor-id="reason-3.-dont-overfit-your-insights-to-the-imprecise-data"><strong>Reason 3. Don’t overfit your insights to the imprecise data</strong></h2>
<p>Overfitting is a major problem to avoid not only when developing statistical models, but also with any analysis of imprecise data. For example, a systolic blood pressure in a 2-year-old child may be measured as 140 (super high), but a wise doctor does not react urgently to it because 2-year-olds often scream like the world is ending when the blood pressure cuff squeezes their arm. The wise doctor will understand the context (was the child screaming?) and gather more data (retake the blood pressure when the kid is calm). If the doctor had immediately given medicine to reduce the blood pressure, she would have overfit her response to the data. The same is true for many analyses in global health. The data will be noisy, tune your insights and actions accordingly.</p>
<p>Aristotle may have lived in 350 BC, but his ancient wisdom can inform data science practice today. His insight has endured through the ages because it makes a fundamental point about how we learn from data in the presence of uncertainty. Anyone engaged in learning from data would do well to listen.</p>


</section>

 ]]></description>
  <category>Data Science + Global Health</category>
  <guid>https://www.thedoctorsdialectic.com/docs/posts/2022-03-19-aristotle-and-data-science/index.en.html</guid>
  <pubDate>Sat, 19 Mar 2022 05:00:00 GMT</pubDate>
</item>
<item>
  <title>How to walk the unsexy path toward sophisticated Data Science in Global Health: Data Management</title>
  <dc:creator>Mark Zobeck</dc:creator>
  <link>https://www.thedoctorsdialectic.com/docs/posts/2022-03-18-unsexy-data-management/index.en.html</link>
  <description><![CDATA[ 




<p><strong>Data science has a data problem.</strong></p>
<p>In my last essay, I argued that because data management is boring, hard to do well, and just not sexy compared to the rest of data science, garbage data is a big problem in global health.</p>
<p>The good news is that with a little effort your organization can collect beautiful, high-quality data! Here are 5 steps to design an optimal system for low-resource settings, where data are manually collected from paper charts by limited numbers of people.</p>
<section id="step-1-identify-the-key-questions-your-data-need-to-answer" class="level3">
<h3 class="anchored" data-anchor-id="step-1-identify-the-key-questions-your-data-need-to-answer">Step 1: Identify the key questions your data need to answer</h3>
<p>Questions are the shining light at the end of the data management path. They should guide you every step of the way. Let the questions come from the people who will use your insights. Talk to your leadership, healthcare providers, program staff, and even patients. Even if you only answer one question, if it is valuable enough to the organization then the cost required to answer it will be worth its weight in gold. Find the right question to answer.</p>
</section>
<section id="step-2-develop-a-framework-to-understand-how-to-answer-the-question" class="level3">
<h3 class="anchored" data-anchor-id="step-2-develop-a-framework-to-understand-how-to-answer-the-question">Step 2: Develop a framework to understand how to answer the question</h3>
<p>Your team needs to understand the various factors that influence the question you are trying to answer. There are several types of frameworks that can be helpful. Google “conceptual framework for monitoring and evaluation”, “results framework”, or “logic models” to learn more. Content experts should be intimately involved in the construction of the framework.</p>
</section>
<section id="step-3---key-step-select-the-right-variables-to-answer-the-question" class="level3">
<h3 class="anchored" data-anchor-id="step-3---key-step-select-the-right-variables-to-answer-the-question">Step 3 - KEY STEP!: Select the right variables to answer the question</h3>
<p>This step is crucial for your success. From the framework, you should understand which variables will be important to answer the question. If you have limited resources to collect data, then you need to be extremely choosy about which variables to collect. Here are four points of advice for variable choice:</p>
<ul>
<li><p>Keep the variables per patient limited. An extremely rough guestimate is 20-30 data points per patient x 15 patients per week is probably the max for one person, although this can vary widely depending on the complexity of the data, how well the data are stored in the chart, and how easy the data are to enter into your database.</p></li>
<li><p>Choose high signal, low noise variables. Dates are great. Easy to define, low measurement error, and chock full of information so that they can be combined in a lot of ways to give precise time spans. Things that are easy to identify and count are also nice (new cancer patients, easy to count; number of new pneumonia diagnoses each week, hard to count).</p></li>
<li><p>Find the right level of specificity. If your data are too high level, they won’t give a useful answer to your question. If they are too granular, the complexity will grind down the quality over time unless you have a lot of help. It is better to have a few accurate data points than a lot of garbage.</p></li>
<li><p>Beware dynamic variables. Variables that change over time are a different animal to collect than variables you can collect once and store forever. Patient outcomes are a necessary dynamic variable that is worth collecting. Collect more at your own risk.</p></li>
</ul>
</section>
<section id="step-4-make-a-data-dictionary-and-share-it-widely" class="level3">
<h3 class="anchored" data-anchor-id="step-4-make-a-data-dictionary-and-share-it-widely">Step 4: Make a data dictionary and share it widely</h3>
<p>As precisely as you are able, define each variable. This is important especially when nonclinical personnel are collecting data. Precise definitions cut down on measurement error, which will make your analyses more accurate and precise. Provide standard answer choices as much as possible. Enforce a data convention. I recommend YYYY-MM-DD for all dates.</p>
</section>
<section id="step-5-create-a-database.-avoid-spreadsheets." class="level3">
<h3 class="anchored" data-anchor-id="step-5-create-a-database.-avoid-spreadsheets.">Step 5: Create a database. Avoid spreadsheets.</h3>
<p>Spreadsheets always seem like a good idea at first, but they have too many degrees of freedom and are highly likely to mutate over a year or two of use. Investigate Microsoft Access, REDCap, or DHIS2 to see if they meet your needs. The latter two are free and amazing. There are other software solutions out there as well. Make sure you have API access (your future sophisticated data science self will thank you). It is worth your time and effort to learn to use one and integrate it into your organization’s operations.</p>
<p>Each of these steps are powerful and incredibly effective in isolation, but together they will produce beautiful, high-quality data that will answer many questions to improve the care you provide to your patients.</p>


</section>

 ]]></description>
  <category>Data Science + Global Health</category>
  <guid>https://www.thedoctorsdialectic.com/docs/posts/2022-03-18-unsexy-data-management/index.en.html</guid>
  <pubDate>Fri, 18 Mar 2022 05:00:00 GMT</pubDate>
</item>
<item>
  <title>Data Science has a garbage problem</title>
  <dc:creator>Mark Zobeck</dc:creator>
  <link>https://www.thedoctorsdialectic.com/docs/posts/2022-03-17-data-science-garbage/index.en.html</link>
  <description><![CDATA[ 




<p><strong>Data science has a data problem.</strong></p>
<p>The vast edifice of technologies, visualizations, statistics, machine learning algorithms that make up the data science empire are built on a foundation that can either be as solid as a rock or as unstable as shifting sand.</p>
<section id="the-foundation-of-all-of-data-science-is-data-quality" class="level2">
<h2 class="anchored" data-anchor-id="the-foundation-of-all-of-data-science-is-data-quality"><strong>The foundation of all of data science is data quality</strong></h2>
<p>If your data are garbage, then your analyses may as well be toxic waste. You are better off hiring a hard Sci-Fi novelist to imagine what insights you might have gotten from possible analyses than performing any of your own. You can literally produce negative information (information that moves you further from your goal) using bad data.</p>
</section>
<section id="garbage-data-is-a-big-problem-in-global-health" class="level2">
<h2 class="anchored" data-anchor-id="garbage-data-is-a-big-problem-in-global-health"><strong>Garbage data is a big problem in Global Health</strong></h2>
<p>Information technologies are limited or nonexistent, and data collection is performed manually. There may be limited time and resources to dedicate toward the inglorious task of data management. Leadership may not understand the value of clean data and may encourage shortcuts that compromise quality. To put it bluntly, data management is boring, hard to do well, and just not sexy compared to the rest of data science.</p>
<p>This is a problem when resources and time are scarce because the wasted effort to collect garbage data is effort that could have been spent on something more valuable.</p>
</section>
<section id="garbage-data-today-will-poison-data-science-tomorrow" class="level2">
<h2 class="anchored" data-anchor-id="garbage-data-today-will-poison-data-science-tomorrow"><strong>Garbage data today will poison data science tomorrow</strong></h2>
<p>As bad analyses accrue over time, a perception will emerge in the organization that data collection is administrative busywork, and the data are untrustworthy and useless for practical applications. This will make future efforts toward data science even more difficult.</p>
</section>
<section id="the-good-news-is-that-garbage-data-can-be-cleaned-up" class="level2">
<h2 class="anchored" data-anchor-id="the-good-news-is-that-garbage-data-can-be-cleaned-up"><strong>The good news is that garbage data can be cleaned up!</strong></h2>
<p>With a little effort, your organization can collect beautiful, high-quality data! Thoughtful data management designed to work within the constraints of the organization’s data collection infrastructure is key. Even if time and resources are limited, you can still ask and answer incredibly important questions from the data in a way that is useful for practice application and builds trust among people who lost confidence in data-driven insights.</p>
<p>In my next post, I’ll give you a few key steps to collect and maintain beautiful, gloriously-insightful data.</p>


</section>

 ]]></description>
  <category>Data Science + Global Health</category>
  <guid>https://www.thedoctorsdialectic.com/docs/posts/2022-03-17-data-science-garbage/index.en.html</guid>
  <pubDate>Thu, 17 Mar 2022 05:00:00 GMT</pubDate>
</item>
</channel>
</rss>
